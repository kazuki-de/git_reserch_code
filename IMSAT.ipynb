{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMSAT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazuki-de/git_reserch_code/blob/master/IMSAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZF0xNLHyAw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation , Softmax, MaxPool2D,UpSampling2D\n",
        "from tensorflow.keras import Model\n",
        "import datetime\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3EGpbKQyI-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c576a34-b515-4189-875d-2a9353f7a056"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNRCFB4gyP-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dc53678-c1da-4dcb-b734-4f0f65af8c82"
      },
      "source": [
        "cd  /content/drive/My Drive/logs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X89NCoRJyQtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/content/drive/My Drive/logs/gradient_tape\", histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EFp0LOSkDhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = Conv2D(32, 3, activation='relu',)\n",
        "        \n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation='relu')\n",
        "        self.d2 = Dense(10)\n",
        "        \n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        return self.d2(x)\n",
        "\n",
        "model1 = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdDBcUNq0yCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence(q_logit, p_logit):\n",
        "    qlogq = tf.reduce_sum(q_logit * tf.math.log(q_logit), axis=1)\n",
        "    qlogp = tf.reduce_sum(q_logit * tf.math.log(p_logit), axis=1)\n",
        "    return qlogq - qlogp\n",
        "def get_unit_vector(v):\n",
        "    return  v / (tf.sqrt(tf.reduce_sum(v ** 2, axis=None,keepdims=True) + 1e-16))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmenScDRzq_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VAT_KL(input_tensor, network, xi=10, epsilon=1.0, weight=1.0, num_approximation=1, clip_value_min=1e-16, dtype=tf.float64):\n",
        "    \n",
        "    #配列内の数値の最大値が第二変数になるように置き換える\n",
        "    #clipped = lambda x: tf.maximum(x, clip_value_min)\n",
        "    #axis_without_batch_size は (1,2,3)となる\n",
        "    #axis_without_batch_size = tuple(range(1,len(input_tensor.get_shape())))\n",
        "    \n",
        "    #if len(axis_without_batch_size) == 1:\n",
        "    #    axis_without_batch_size = axis_without_batch_size[0]\n",
        "        \n",
        "    #normalized = lambda x: x / clipped(tf.norm(x, axis=None))\n",
        "    #normalized = lambda x: x / clipped(tf.norm(x, axis=None,keepdims=True))\n",
        "    #normalized = lambda x: x / tf.norm(x, axis=None,keepdims=True)\n",
        "    plain_softmax = network(input_tensor)\n",
        "    \n",
        "    noplain_softmax = Activation(\"softmax\")(plain_softmax)\n",
        "    \n",
        "    #適当な単位ベクトルにxi=10を掛けた数:pertubationの作成\n",
        "    perturbation = xi * get_unit_vector(tf.random.normal(shape=tf.shape(input_tensor), dtype=dtype))\n",
        "    #print(perturbation.numpy())\n",
        "    \n",
        "    for i in range(num_approximation):\n",
        "        \n",
        "        softmax_accommodating_perturbation = network(input_tensor+perturbation)\n",
        "        \n",
        "        softmax_accommodating_perturbation_af = Activation(\"softmax\")(softmax_accommodating_perturbation)\n",
        "        # ノイズを足した配列とノーマルな配列がCNNで出力された結果のKL距離を求める\n",
        "        dist = kl_divergence(noplain_softmax,softmax_accommodating_perturbation_af)\n",
        "        #cross_entropy_accommodating_perturbation = -tf.reduce_sum(plain_softmax * tf.math.log(clipped(softmax_accommodating_perturbation))) * weight\n",
        "        adversarial_direction = tf.gradients(dist, [perturbation])[0]\n",
        "        pertubation = tf.stop_gradient(adversarial_direction)\n",
        "    #print(\"ok\")    \n",
        "    \n",
        "    pertubation = epsilon * get_unit_vector(pertubation)\n",
        "    corrent_softmax = Activation(\"softmax\")(network(input_tensor)) \n",
        "    vat_softmax = Activation(\"softmax\")(network(input_tensor + perturbation))\n",
        "    loss =  -kl_divergence(corrent_softmax,vat_softmax)\n",
        "    return  loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fdnl19iDr7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_entropy(p):\n",
        "    return - tf.reduce_sum(p*tf.math.log(p+1e-16),axis = 1)\n",
        "\n",
        "def compute_marginal_entropy(p_batch):\n",
        "    return  compute_entropy(tf.reduce_mean(p_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qne_U9p5auUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#損失関数\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "#最適化手法\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "#評価関数\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_loss1 = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_loss2 = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2b7AlZVoXDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ミニバッチ学習==1epocでn枚の画像からx枚ずつ取り出しn/x回学習する(重みを更新していく)手法\n",
        "#バッチ学習 == 1epocでn枚の画像から1枚ずつ取り出しn回学習する（重みを更新していく）手法\n",
        "#オンライン学習 ==1epocでn枚の画像からn枚全てを用い学習する(重みを更新していく)手法　#メモリ消費大\n",
        "@tf.function\n",
        "def train_step(image,label,batch_size):\n",
        "    with tf.GradientTape() as tape:\n",
        "        p = Activation('softmax')(model1(image))\n",
        "        hy_ = compute_entropy(p)\n",
        "        hy = tf.reduce_mean(hy_)\n",
        "        p_ave = tf.reduce_mean(p,axis=0)\n",
        "        hy_x = -tf.reduce_sum(p_ave*tf.math.log(p_ave+1e-16))\n",
        "        #print(hy)\n",
        "        #hy_x = tf.reduce_sum(compute_entropy(p))/batch_size\n",
        "        #print(hy_x)\n",
        "        Rsut = -tf.reduce_sum(VAT_KL(image,model1))/batch_size\n",
        "        #print(Rsut)\n",
        "        loss = Rsut - 0.2*((4.0)*hy-hy_x)\n",
        "    gradients = tape.gradient(loss, model1.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model1.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    #train_loss1(Rsut)\n",
        "    #train_loss2(0.2*((4.0)*hy-hy_x))\n",
        "    #train_loss(loss)\n",
        "    #train_loss\n",
        "    \n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNk17qRXbK5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(100)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uXj-nnVgv8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "940174d3-5298-4fa0-fbcb-fd18f9021453"
      },
      "source": [
        "%pip install munkres\n",
        "from munkres import Munkres, print_matrix"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: munkres in /usr/local/lib/python3.6/dist-packages (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLc0Gss0ZwKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(y_pred, y_t,tot_cl=10):\n",
        "    # compute the accuracy using Hungarian algorithm\n",
        "    m = Munkres()\n",
        "    mat = np.zeros((tot_cl, tot_cl))\n",
        "    for i in range(tot_cl):\n",
        "        for j in range(tot_cl):\n",
        "            mat[i][j] = np.sum(np.logical_and(y_pred == i, y_t == j))\n",
        "    indexes = m.compute(-mat)\n",
        "\n",
        "    corresp = []\n",
        "    for i in range(tot_cl):\n",
        "        corresp.append(indexes[i][1])\n",
        "\n",
        "    pred_corresp = [corresp[predicte] for predicted in y_pred]\n",
        "    acc = np.sum(pred_corresp == y_t) / float(len(y_t))\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHk9axm2bJJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8ee34e4e-645a-42de-b13f-d231e359198f"
      },
      "source": [
        "epoc =20\n",
        "for i in range(epoc):\n",
        "    for image,label in train_ds:\n",
        "        train_step(image,label,100)\n",
        "    #print( train_loss1.result())  \n",
        "    #print( train_loss2.result())\n",
        "    print( train_loss.result())\n",
        "    #print(compute_accuracy(np.argmax(Activation('softmax')(model1(x_train)).astype(np.float32),y_train.astype(np.float32).,10))\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(-1.3813661, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3814718, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3815118, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3815318, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3815409, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3815087, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3814857, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3814684, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.381455, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3814498, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.381485, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3815142, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.381539, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3815602, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3815786, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3815947, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3816088, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3816215, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3816327, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.3816314, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycTXOjlU6g_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ff038d29-2aad-4156-f9ac-92f26afae803"
      },
      "source": [
        "Activation('softmax')(model1(x_train[1:10]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=25805, shape=(9, 10), dtype=float64, numpy=\n",
              "array([[0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ],\n",
              "       [0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ],\n",
              "       [0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ],\n",
              "       [0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ],\n",
              "       [0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ],\n",
              "       [0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ],\n",
              "       [0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ],\n",
              "       [0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ],\n",
              "       [0.1000011 , 0.09999994, 0.0999999 , 0.09999994, 0.10000285,\n",
              "        0.09999996, 0.09999986, 0.09999988, 0.09999796, 0.0999986 ]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk3TXST5i1Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}