{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazuki-de/git_reserch_code/blob/master/Autoencoder_tensorflow2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykHH0Fe-VxxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation , Softmax, MaxPool2D,UpSampling2D\n",
        "from tensorflow.keras import Model\n",
        "import datetime\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEMQiEZoAP5S",
        "colab_type": "code",
        "outputId": "98622f29-caab-44fc-851a-ab4e6293fd7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x = tf.Constant(1,shape=(),dtype=tf.int32)\n",
        "tf.executing_eagerly()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ2-Q4obUMWE",
        "colab_type": "code",
        "outputId": "75373f69-dc17-49c6-baaa-e482a6e168c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwzy9HdeopwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVWUb5FH3xsE",
        "colab_type": "code",
        "outputId": "2baa8c0f-999b-47b7-b403-0502b5c23e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd  /content/drive/My Drive/logs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FGDAWQH3Jpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.TextLineDataset(\"/content/drive/My Drive/2048_tissue_choice/sumpling_20csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IGDQK8i3QnM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c80c53c6-4471-4e79-bc93-9f5483e7134b"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TextLineDatasetV2 shapes: (), types: tf.string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx3PxvdVSt5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/content/drive/My Drive/logs/gradient_tape\", histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64xfXzIRPucv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/2048pix_tissue_choice/sumpling_20.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngCop5l7PvIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel1(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel1, self).__init__()\n",
        "        self.Conv1 = Conv2D(4,(7,7),padding=\"same\", activation='relu')\n",
        "        self.Maxpool1 = MaxPool2D((2, 2), padding='same')\n",
        "        self.Conv2 = Conv2D(8,(5,5), padding=\"same\",activation='relu')\n",
        "        self.Maxpool2 = MaxPool2D((2, 2), padding='same')\n",
        "        self.Conv3 = Conv2D(16,(3,3),padding=\"same\", activation='relu')\n",
        "        self.Maxpool3 = MaxPool2D((2, 2), padding='same')\n",
        "        \n",
        "        self.Conv4 = Conv2D(16,(3,3),padding=\"same\", activation='relu')\n",
        "        self.Upsumpl1 = UpSampling2D((2, 2))\n",
        "        self.Conv5 = Conv2D(8,(5,5), padding='same',activation='relu')\n",
        "        self.Upsumpl2 = UpSampling2D((2, 2))\n",
        "        self.Conv6 = Conv2D(4,(7,7), padding='same',activation='relu')\n",
        "        self.Upsumpl3 = UpSampling2D((2, 2))\n",
        "        self.Conv7 = Conv2D(3,(3,3), padding='same',activation='relu')\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.Conv1(x)\n",
        "        x = self.Maxpool1(x)\n",
        "        x = self.Conv2(x)\n",
        "        x = self.Maxpool2(x)\n",
        "        x = self.Conv3(x)\n",
        "        x = self.Maxpool3(x)\n",
        "        x = self.Conv4(x)\n",
        "        x = self.Upsumpl1(x)\n",
        "        x = self.Conv5(x)\n",
        "        x = self.Upsumpl2(x)\n",
        "        x = self.Conv6(x)\n",
        "        x = self.Upsumpl3(x)\n",
        "        return self.Conv7(x)\n",
        "\n",
        "model1 = MyModel1()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Yqoxwxrl64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#損失関数\n",
        "loss_object = tf.keras.losses.MeanSquaredError()\n",
        "#最適化手法\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "#評価関数\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-bUq-I80dPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(image):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model1(image)\n",
        "        #softmax = Activation('softmax')(predictions)\n",
        "        loss = loss_object(image, predictions)\n",
        "        #VAT_loss = VAT_KL(image,model2)\n",
        "        #print(loss.numpy())\n",
        "        #print(loss.shape)\n",
        "        #loss_add = loss + VAT_loss\n",
        "    gradients = tape.gradient(loss, model1.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model1.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    #train_accuracy(label, )\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def test_step(image):\n",
        "    predictions = model1(image)\n",
        "    #softmax = Activation('softmax')(predictions)\n",
        "    t_loss = loss_object(image, predictions)\n",
        "\n",
        "    test_loss(t_loss)\n",
        "    #test_accuracy(label, softmax)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYHa5emv9kVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/2048pix_tissue_choice/sumpling_20.csv\"\n",
        "def generater_train():\n",
        "    file_path1 = pd.read_csv(\"/content/drive/My Drive/2048pix_tissue_choice/tran_6000.csv\")\n",
        "    \n",
        "    # LabelEncode(classをint型に変換)するためのdict\\n\",\n",
        "    classes =[\"PI\",\"PP\",\"TRU\"]\n",
        "    classes = {v: i for i, v in enumerate(sorted(classes))}\n",
        "    #file_path1 = pd.read_csv(file_path)\n",
        "    length = len(file_path1)\n",
        "    for i in range(length):\n",
        "        path = file_path1.loc[i][\"path1\"]\n",
        "        with Image.open(path) as f:\n",
        "                tmp_image = np.asarray(f, dtype=np.float32)/255\n",
        "        label = file_path1.loc[i][\"type\"]\n",
        "        tmp_label = tf.keras.utils.to_categorical(classes[label],len(classes))\n",
        "        #print(tmp_labels, np.mean(tmp_images, axis=(1,2,3)))\n",
        "        yield tmp_image, tmp_label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwl59tVaKhIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generater_val():\n",
        "    file_path1 = pd.read_csv(\"/content/drive/My Drive/2048pix_tissue_choice/val_1000.csv\")\n",
        "    \n",
        "    # LabelEncode(classをint型に変換)するためのdict\\n\",\n",
        "    classes =[\"PI\",\"PP\",\"TRU\"]\n",
        "    classes = {v: i for i, v in enumerate(sorted(classes))}\n",
        "    #file_path1 = pd.read_csv(file_path)\n",
        "    length = len(file_path1)\n",
        "    for i in range(length):\n",
        "        path = file_path1.loc[i][\"path1\"]\n",
        "        with Image.open(path) as f:\n",
        "                tmp_image = np.asarray(f, dtype=np.float32)/255\n",
        "        label = file_path1.loc[i][\"type\"]\n",
        "        tmp_label = tf.keras.utils.to_categorical(classes[label],len(classes))\n",
        "        #print(tmp_labels, np.mean(tmp_images, axis=(1,2,3)))\n",
        "        yield tmp_image, tmp_label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33iOeDeN0hc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200\n",
        "#model = MyModel()\n",
        "batchsize = 10\n",
        "dataset_t = tf.data.Dataset.from_generator(generater_train, (tf.float32, tf.float32)).batch(20)\n",
        "dataset_v = tf.data.Dataset.from_generator(generater_val, (tf.float32, tf.float32)).batch(20)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for batch, (x_t,x_l) in enumerate(dataset_t):\n",
        "        train_step(x_t)\n",
        "        print(batch)\n",
        "    #with train_summary_writer.as_default():\n",
        "        #tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "        #tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
        "    \n",
        "    \n",
        "    for batch, (y_t,y_l) in enumerate(dataset_t):\n",
        "        test_step(y_t)\n",
        "    #with test_summary_writer.as_default():\n",
        "        #tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "        #tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
        "\n",
        "    template = 'Epoch {}, Loss: {}, Test Loss: {}'\n",
        "    print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         #train_accuracy.result()*100,\n",
        "                         test_loss.result()\n",
        "                         #test_accuracy.result()*100)\n",
        "                          ))\n",
        "    \n",
        "#train_loss.reset_states()\n",
        "#test_loss.reset_states()\n",
        "#train_accuracy.reset_states()\n",
        "#test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaFNfTb09gjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def our_generator():\n",
        "    for i in range(1000):\n",
        "      x = np.random.rand(28,28)\n",
        "      y = np.random.randint(1,10, size=1)\n",
        "      yield x,y\n",
        "    \n",
        "dataset = tf.data.Dataset.from_generator(our_generator, (tf.float32, tf.int16))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEDU1r8a-Usy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "outputId": "f7a25adf-9463-4761-eec6-70312157d878"
      },
      "source": [
        "dataset_t = tf.data.Dataset.from_generator(generater_train, (tf.float32, tf.float32))\n",
        "for batch, (x,y) in enumerate(dataset_t.batch(10)):\n",
        "    print(batch)\n",
        "    print(y)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-5f7a6e6e2ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerater_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \"\"\"\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2118\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: FileNotFoundError: [Errno 2] File b'/content/drive/My Drive/2048pix_tissue_choice/train_6000.csv' does not exist: b'/content/drive/My Drive/2048pix_tissue_choice/train_6000.csv'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 209, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 525, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-95-023132d95011>\", line 3, in generater_train\n    file_path1 = pd.read_csv(\"/content/drive/My Drive/2048pix_tissue_choice/train_6000.csv\")\n\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 702, in parser_f\n    return _read(filepath_or_buffer, kwds)\n\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 429, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 895, in __init__\n    self._make_engine(self.engine)\n\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\", line 1853, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n\n  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n\n  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n\nFileNotFoundError: [Errno 2] File b'/content/drive/My Drive/2048pix_tissue_choice/train_6000.csv' does not exist: b'/content/drive/My Drive/2048pix_tissue_choice/train_6000.csv'\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNextSync]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohRxNF-WD-hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}