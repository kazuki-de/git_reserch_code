{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAT＿KL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazuki-de/git_reserch_code/blob/master/VAT%EF%BC%BFKL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCE3_56QPtXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation , Softmax\n",
        "from tensorflow.keras import Model\n",
        "import datetime\n",
        "import tensorflow_probability as tfp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ2-Q4obUMWE",
        "colab_type": "code",
        "outputId": "2a36a1f4-c16d-4294-87d7-abc46cf54f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwzy9HdeopwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVWUb5FH3xsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "586096d0-a30b-47e0-bc12-9d59f35ce2e4"
      },
      "source": [
        "cd  drive/My Drive/logs"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx3PxvdVSt5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/content/drive/My Drive/logs/gradient_tape\", histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64xfXzIRPucv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A81d2KwCGdNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ラベルのカテゴリカル化\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ9so2oMPuz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i2NHRbcHewi",
        "colab_type": "code",
        "outputId": "62acf4a4-5e0c-48be-e2b1-6f28e3dc47a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngCop5l7PvIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation='relu')\n",
        "        self.d2 = Dense(10)\n",
        "        \n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        return self.d2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfxRcCuXPvcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#損失関数\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "#最適化手法\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "#評価関数\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH2j2R58SJa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VAT_cifar10(input_tensor, network, xi=1e-6, epsilon=2.0, weight=1.0, num_approximation=1, clip_value_min=1e-30, dtype=tf.float64):\n",
        "    #tf.reduce_sum 配列内の対応した数を足しあわせる\n",
        "    clipped = lambda x: tf.maximum(x, clip_value_min)\n",
        "\n",
        "    axis_without_batch_size = tuple(range(1,len(input_tensor.get_shape())))\n",
        "    if len(axis_without_batch_size) == 1: axis_without_batch_size = axis_without_batch_size[0]\n",
        "    normalized = lambda x: x / clipped(tf.norm(x, axis=None))\n",
        "    plain_softmax = network(input_tensor)\n",
        "    perturbation = xi * normalized(tf.random.normal(shape=tf.shape(input_tensor), dtype=dtype))\n",
        "    for i in range(num_approximation):\n",
        "        softmax_accommodating_perturbation = network(input_tensor+perturbation)\n",
        "        #8/8----------------------------------------------------------------------------------------------------\n",
        "        \n",
        "        cross_entropy_accommodating_perturbation = -tf.reduce_sum(plain_softmax * tf.math.log(clipped(softmax_accommodating_perturbation))) * weight\n",
        "        adversarial_direction = tf.gradients(cross_entropy_accommodating_perturbation, [perturbation])[0]\n",
        "        vat_perturbation = normalized(adversarial_direction)\n",
        "        perturbation = xi * vat_perturbation\n",
        "        \n",
        "        \n",
        "    current_softmax = Activation('softmax')(network(input_tensor)) \n",
        "    current_softmax = tf.stop_gradient(current_softmax)\n",
        "    vat_perturbation = tf.stop_gradient(epsilon * vat_perturbation)\n",
        "    vat_softmax = Activation('softmax')(network(input_tensor + vat_perturbation))\n",
        "    print(current_softmax)\n",
        "    bbb=tf.cast(tf.reduce_sum(weight)+1e-30, tf.float64)\n",
        "    \n",
        "    vat_cross_entropy = tf.reduce_sum(-tf.reduce_sum(current_softmax * tf.math.log(clipped(vat_softmax))) * weight) / bbb\n",
        "    return vat_cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fQKiusK4lfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VAT_mnist(input_tensor, network, xi=1e-6, epsilon=2.0, weight=1.0, num_approximation=1, clip_value_min=1e-30, dtype=tf.float64):\n",
        "    \n",
        "    #配列内の数値の最大値が最大第二変数になるように置き換える\n",
        "    clipped = lambda x: tf.maximum(x, clip_value_min)\n",
        "    #axis_without_batch_size は (1,2,3)となる\n",
        "    axis_without_batch_size = tuple(range(1,len(input_tensor.get_shape())))\n",
        "    \n",
        "    if len(axis_without_batch_size) == 1:\n",
        "        axis_without_batch_size = axis_without_batch_size[0]\n",
        "        \n",
        "    #normalized = lambda x: x / clipped(tf.norm(x, axis=None))\n",
        "    normalized = lambda x: x / clipped(tf.norm(x, axis=None,keepdims=True))\n",
        "    \n",
        "    plain_softmax = network(input_tensor)\n",
        "    perturbation = xi * normalized(tf.random.normal(shape=tf.shape(input_tensor), dtype=dtype))\n",
        "    for i in range(num_approximation):\n",
        "        softmax_accommodating_perturbation = network(input_tensor+perturbation)\n",
        "        #8/8----------------------------------------------------------------------------------------------------\n",
        "         #tf.reduce_sum それぞれの配列内に対応した数を足しあわせる\n",
        "        cross_entropy_accommodating_perturbation = -tf.reduce_sum(plain_softmax * tf.math.log(clipped(softmax_accommodating_perturbation))) * weight\n",
        "        print(cross_entropy_accommodating_perturbation)\n",
        "        adversarial_direction = tf.gradients(cross_entropy_accommodating_perturbation, [perturbation])[0]\n",
        "        vat_perturbation = normalized(adversarial_direction)\n",
        "        perturbation = xi * vat_perturbation\n",
        "        \n",
        "        \n",
        "    current_softmax = Activation('softmax')(network(input_tensor)) \n",
        "    current_softmax = tf.stop_gradient(current_softmax)\n",
        "    vat_perturbation = tf.stop_gradient(epsilon * perturbation)\n",
        "    vat_softmax = Activation('softmax')(network(input_tensor + perturbation))\n",
        "    #print(current_softmax)\n",
        "    bbb=tf.cast(tf.reduce_sum(weight)+1e-30, tf.float64)\n",
        "    \n",
        "    vat_cross_entropy = tf.reduce_sum(-tf.reduce_sum(current_softmax * tf.math.log(clipped(vat_softmax))) * weight) / bbb\n",
        "    return vat_cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlJtKllpOtkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence(q_logit, p_logit):\n",
        "    qlogq = tf.reduce_mean(tf.reduce_sum(q_logit * tf.math.log(q_logit), 1))\n",
        "    qlogp = tf.reduce_mean(tf.reduce_sum(q_logit * tf.math.log(p_logit), 1))\n",
        "    return qlogq - qlogp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDJqz-OfJLkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VAT_KL(input_tensor, network, xi=10, epsilon=1.0, weight=1.0, num_approximation=1, clip_value_min=1e-30, dtype=tf.float64):\n",
        "    \n",
        "    #配列内の数値の最大値が第二変数になるように置き換える\n",
        "    clipped = lambda x: tf.maximum(x, clip_value_min)\n",
        "    #axis_without_batch_size は (1,2,3)となる\n",
        "    #axis_without_batch_size = tuple(range(1,len(input_tensor.get_shape())))\n",
        "    \n",
        "    #if len(axis_without_batch_size) == 1:\n",
        "    #    axis_without_batch_size = axis_without_batch_size[0]\n",
        "        \n",
        "    #normalized = lambda x: x / clipped(tf.norm(x, axis=None))\n",
        "    normalized = lambda x: x / clipped(tf.norm(x, axis=None,keepdims=True))\n",
        "    \n",
        "    plain_softmax = network(input_tensor)\n",
        "    \n",
        "    noplain_softmax = Activation(\"softmax\")(plain_softmax)\n",
        "    \n",
        "    #適当な単位ベクトルにxi=10を掛けた数:pertubationの作成\n",
        "    perturbation = xi * normalized(tf.random.normal(shape=tf.shape(input_tensor), dtype=dtype))\n",
        "    \n",
        "    \n",
        "    for i in range(num_approximation):\n",
        "        \n",
        "        softmax_accommodating_perturbation = network(input_tensor+perturbation)\n",
        "        softmax_accommodating_perturbation_af = Activation(\"softmax\")(softmax_accommodating_perturbation)\n",
        "        # ノイズを足した配列とノーマルな配列がCNNで出力された結果のKL距離を求める\n",
        "        dist = kl_divergence(noplain_softmax,softmax_accommodating_perturbation_af)\n",
        "        #cross_entropy_accommodating_perturbation = -tf.reduce_sum(plain_softmax * tf.math.log(clipped(softmax_accommodating_perturbation))) * weight\n",
        "        adversarial_direction = tf.gradients(dist, [perturbation])[0]\n",
        "        pertubation = tf.stop_gradient(adversarial_direction)\n",
        "    print(\"ok\")    \n",
        "    pertubation = epsilon * normalized(pertubation)\n",
        "    corrent_softmax = Activation('softmax')(network(input_tensor)) \n",
        "    vat_softmax = Activation('softmax')(network(input_tensor + perturbation))\n",
        "    loss = kl_divergence(corrent_softmax,vat_softmax)\n",
        "    return loss\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olvRqss-Pvu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(image, label):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(image)\n",
        "        softmax = Activation('softmax')(predictions)\n",
        "        loss = loss_object(label, softmax)\n",
        "        print(\"ok\")\n",
        "        VAT_loss = VAT_KL(image,model)\n",
        "        loss_add = loss + VAT_loss\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(label, softmax)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def test_step(image, label):\n",
        "    predictions = model(image)\n",
        "    softmax = Activation('softmax')(predictions)\n",
        "    t_loss = loss_object(label, softmax)\n",
        "\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(label, softmax)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNlKJ8hfPwCM",
        "colab_type": "code",
        "outputId": "6fe1e5e8-1851-4e19-b38c-f8d422fc96ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 200\n",
        "model = MyModel()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for image, label in train_ds:\n",
        "        train_step(image, label)\n",
        "    #with train_summary_writer.as_default():\n",
        "        #tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "        #tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
        "    \n",
        "    \n",
        "    for test_image, test_label in test_ds:\n",
        "        test_step(test_image, test_label)\n",
        "    #with test_summary_writer.as_default():\n",
        "        #tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "        #tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
        "\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100))\n",
        "    \n",
        "train_loss.reset_states()\n",
        "test_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "ok\n",
            "ok\n",
            "ok\n",
            "Epoch 1, Loss: 1.2917832136154175, Accuracy: 67.74617767333984, Test Loss: 1.2741342782974243, Test Accuracy: 69.09000396728516\n",
            "Epoch 2, Loss: 1.2267827987670898, Accuracy: 69.36439514160156, Test Loss: 1.2026535272598267, Test Accuracy: 70.79470825195312\n",
            "Epoch 3, Loss: 1.167425274848938, Accuracy: 70.84461212158203, Test Loss: 1.1391041278839111, Test Accuracy: 72.31777954101562\n",
            "Epoch 4, Loss: 1.1134192943572998, Accuracy: 72.1913070678711, Test Loss: 1.0824114084243774, Test Accuracy: 73.68630981445312\n",
            "Epoch 5, Loss: 1.0641175508499146, Accuracy: 73.42130279541016, Test Loss: 1.0320134162902832, Test Accuracy: 74.91799926757812\n",
            "Epoch 6, Loss: 1.0190017223358154, Accuracy: 74.54605102539062, Test Loss: 0.9869645833969116, Test Accuracy: 76.03475952148438\n",
            "Epoch 7, Loss: 0.9775413274765015, Accuracy: 75.58047485351562, Test Loss: 0.9456347227096558, Test Accuracy: 77.04954528808594\n",
            "Epoch 8, Loss: 0.9393025040626526, Accuracy: 76.5347671508789, Test Loss: 0.9081194996833801, Test Accuracy: 77.9791259765625\n",
            "Epoch 9, Loss: 0.9039477109909058, Accuracy: 77.41686248779297, Test Loss: 0.8733819127082825, Test Accuracy: 78.83333587646484\n",
            "Epoch 10, Loss: 0.8711332678794861, Accuracy: 78.23585510253906, Test Loss: 0.8419812321662903, Test Accuracy: 79.61680603027344\n",
            "Epoch 11, Loss: 0.8406280875205994, Accuracy: 78.99734497070312, Test Loss: 0.8127062916755676, Test Accuracy: 80.34615325927734\n",
            "Epoch 12, Loss: 0.8121944069862366, Accuracy: 79.70745849609375, Test Loss: 0.7865673899650574, Test Accuracy: 81.00666046142578\n",
            "Epoch 13, Loss: 0.7856370806694031, Accuracy: 80.37064361572266, Test Loss: 0.7614002227783203, Test Accuracy: 81.63642883300781\n",
            "Epoch 14, Loss: 0.7607432007789612, Accuracy: 80.99165344238281, Test Loss: 0.7389306426048279, Test Accuracy: 82.210693359375\n",
            "Epoch 15, Loss: 0.7373701333999634, Accuracy: 81.57535552978516, Test Loss: 0.7179277539253235, Test Accuracy: 82.7473373413086\n",
            "Epoch 16, Loss: 0.7154090404510498, Accuracy: 82.12368774414062, Test Loss: 0.6980094909667969, Test Accuracy: 83.24903106689453\n",
            "Epoch 17, Loss: 0.6946840286254883, Accuracy: 82.64128112792969, Test Loss: 0.6792586445808411, Test Accuracy: 83.72437286376953\n",
            "Epoch 18, Loss: 0.6751627922058105, Accuracy: 83.12908172607422, Test Loss: 0.6621531248092651, Test Accuracy: 84.16636657714844\n",
            "Epoch 19, Loss: 0.6567068099975586, Accuracy: 83.58973693847656, Test Loss: 0.6459919810295105, Test Accuracy: 84.58735656738281\n",
            "Epoch 20, Loss: 0.6392000317573547, Accuracy: 84.02701568603516, Test Loss: 0.6309195160865784, Test Accuracy: 84.98714447021484\n",
            "Epoch 21, Loss: 0.6226404905319214, Accuracy: 84.4405746459961, Test Loss: 0.6166025996208191, Test Accuracy: 85.36111450195312\n",
            "Epoch 22, Loss: 0.6068938374519348, Accuracy: 84.83406066894531, Test Loss: 0.6033244729042053, Test Accuracy: 85.7148666381836\n",
            "Epoch 23, Loss: 0.5919475555419922, Accuracy: 85.20741271972656, Test Loss: 0.5906128287315369, Test Accuracy: 86.04841613769531\n",
            "Epoch 24, Loss: 0.5777043700218201, Accuracy: 85.56336975097656, Test Loss: 0.5781825184822083, Test Accuracy: 86.3728256225586\n",
            "Epoch 25, Loss: 0.5641232132911682, Accuracy: 85.90287780761719, Test Loss: 0.566635012626648, Test Accuracy: 86.67424774169922\n",
            "Epoch 26, Loss: 0.5511718988418579, Accuracy: 86.22639465332031, Test Loss: 0.5558860898017883, Test Accuracy: 86.96341705322266\n",
            "Epoch 27, Loss: 0.5388162136077881, Accuracy: 86.53482818603516, Test Loss: 0.5461165904998779, Test Accuracy: 87.23429107666016\n",
            "Epoch 28, Loss: 0.526987612247467, Accuracy: 86.83029174804688, Test Loss: 0.5363694429397583, Test Accuracy: 87.49744415283203\n",
            "Epoch 29, Loss: 0.5156767964363098, Accuracy: 87.1129379272461, Test Loss: 0.5271865129470825, Test Accuracy: 87.74750518798828\n",
            "Epoch 30, Loss: 0.5048511028289795, Accuracy: 87.3830795288086, Test Loss: 0.5186606049537659, Test Accuracy: 87.98688507080078\n",
            "Epoch 31, Loss: 0.49444496631622314, Accuracy: 87.64307403564453, Test Loss: 0.5103636980056763, Test Accuracy: 88.21869659423828\n",
            "Epoch 32, Loss: 0.4845016896724701, Accuracy: 87.89161682128906, Test Loss: 0.5027756690979004, Test Accuracy: 88.4395751953125\n",
            "Epoch 33, Loss: 0.4749363660812378, Accuracy: 88.1305160522461, Test Loss: 0.4953608214855194, Test Accuracy: 88.64895629882812\n",
            "Epoch 34, Loss: 0.4657300114631653, Accuracy: 88.36058044433594, Test Loss: 0.48807406425476074, Test Accuracy: 88.85489654541016\n",
            "Epoch 35, Loss: 0.4568576514720917, Accuracy: 88.58226013183594, Test Loss: 0.4810914397239685, Test Accuracy: 89.05419921875\n",
            "Epoch 36, Loss: 0.4483504891395569, Accuracy: 88.79480743408203, Test Loss: 0.4750369191169739, Test Accuracy: 89.237060546875\n",
            "Epoch 37, Loss: 0.4401280879974365, Accuracy: 89.00019836425781, Test Loss: 0.46858668327331543, Test Accuracy: 89.41480255126953\n",
            "Epoch 38, Loss: 0.43221256136894226, Accuracy: 89.19800567626953, Test Loss: 0.46267634630203247, Test Accuracy: 89.58773803710938\n",
            "Epoch 39, Loss: 0.4245842695236206, Accuracy: 89.38863372802734, Test Loss: 0.45686209201812744, Test Accuracy: 89.7531509399414\n",
            "Epoch 40, Loss: 0.4172208309173584, Accuracy: 89.5726547241211, Test Loss: 0.4512711763381958, Test Accuracy: 89.91727447509766\n",
            "Epoch 41, Loss: 0.4100910723209381, Accuracy: 89.7507553100586, Test Loss: 0.4457712769508362, Test Accuracy: 90.074462890625\n",
            "Epoch 42, Loss: 0.40321892499923706, Accuracy: 89.92266845703125, Test Loss: 0.4404089152812958, Test Accuracy: 90.2235107421875\n",
            "Epoch 43, Loss: 0.3965580463409424, Accuracy: 90.08905792236328, Test Loss: 0.4354420304298401, Test Accuracy: 90.36862182617188\n",
            "Epoch 44, Loss: 0.39012420177459717, Accuracy: 90.24980163574219, Test Loss: 0.4307698905467987, Test Accuracy: 90.50678253173828\n",
            "Epoch 45, Loss: 0.3839074969291687, Accuracy: 90.40528869628906, Test Loss: 0.4263138175010681, Test Accuracy: 90.642333984375\n",
            "Epoch 46, Loss: 0.3778623938560486, Accuracy: 90.55635070800781, Test Loss: 0.42174383997917175, Test Accuracy: 90.77491760253906\n",
            "Epoch 47, Loss: 0.3720094561576843, Accuracy: 90.7025146484375, Test Loss: 0.4174862205982208, Test Accuracy: 90.901611328125\n",
            "Epoch 48, Loss: 0.36633235216140747, Accuracy: 90.84436798095703, Test Loss: 0.41380202770233154, Test Accuracy: 91.02111053466797\n",
            "Epoch 49, Loss: 0.3608405888080597, Accuracy: 90.98148345947266, Test Loss: 0.4102153778076172, Test Accuracy: 91.1390609741211\n",
            "Epoch 50, Loss: 0.35549455881118774, Accuracy: 91.11509704589844, Test Loss: 0.40672600269317627, Test Accuracy: 91.25337982177734\n",
            "Epoch 51, Loss: 0.3503253161907196, Accuracy: 91.24430084228516, Test Loss: 0.40384358167648315, Test Accuracy: 91.36212158203125\n",
            "Epoch 52, Loss: 0.34529829025268555, Accuracy: 91.36997985839844, Test Loss: 0.4003266394138336, Test Accuracy: 91.47179412841797\n",
            "Epoch 53, Loss: 0.340401291847229, Accuracy: 91.49235534667969, Test Loss: 0.39690539240837097, Test Accuracy: 91.57926177978516\n",
            "Epoch 54, Loss: 0.3356405794620514, Accuracy: 91.6113052368164, Test Loss: 0.39399635791778564, Test Accuracy: 91.68347930908203\n",
            "Epoch 55, Loss: 0.33104410767555237, Accuracy: 91.72639465332031, Test Loss: 0.39107391238212585, Test Accuracy: 91.7825698852539\n",
            "Epoch 56, Loss: 0.326543927192688, Accuracy: 91.83879852294922, Test Loss: 0.3885422348976135, Test Accuracy: 91.87789154052734\n",
            "Epoch 57, Loss: 0.32216876745224, Accuracy: 91.94815063476562, Test Loss: 0.3870948851108551, Test Accuracy: 91.96805572509766\n",
            "Epoch 58, Loss: 0.31792035698890686, Accuracy: 92.05438232421875, Test Loss: 0.3846072256565094, Test Accuracy: 92.0573959350586\n",
            "Epoch 59, Loss: 0.313772588968277, Accuracy: 92.1579818725586, Test Loss: 0.38218921422958374, Test Accuracy: 92.14378356933594\n",
            "Epoch 60, Loss: 0.3097303807735443, Accuracy: 92.25904083251953, Test Loss: 0.3800220787525177, Test Accuracy: 92.22840118408203\n",
            "Epoch 61, Loss: 0.30579182505607605, Accuracy: 92.3573989868164, Test Loss: 0.3779194951057434, Test Accuracy: 92.310791015625\n",
            "Epoch 62, Loss: 0.3019542694091797, Accuracy: 92.45321655273438, Test Loss: 0.37538108229637146, Test Accuracy: 92.39299011230469\n",
            "Epoch 63, Loss: 0.29820260405540466, Accuracy: 92.54698944091797, Test Loss: 0.3729718327522278, Test Accuracy: 92.47320556640625\n",
            "Epoch 64, Loss: 0.2945428788661957, Accuracy: 92.63845825195312, Test Loss: 0.3706112205982208, Test Accuracy: 92.55177307128906\n",
            "Epoch 65, Loss: 0.29097190499305725, Accuracy: 92.72769927978516, Test Loss: 0.36830630898475647, Test Accuracy: 92.62850189208984\n",
            "Epoch 66, Loss: 0.2874864935874939, Accuracy: 92.81481170654297, Test Loss: 0.36605536937713623, Test Accuracy: 92.70320892333984\n",
            "Epoch 67, Loss: 0.28408360481262207, Accuracy: 92.89986419677734, Test Loss: 0.3638574182987213, Test Accuracy: 92.77609252929688\n",
            "Epoch 68, Loss: 0.2807603180408478, Accuracy: 92.98292541503906, Test Loss: 0.36171314120292664, Test Accuracy: 92.84735107421875\n",
            "Epoch 69, Loss: 0.27751386165618896, Accuracy: 93.0640640258789, Test Loss: 0.3596230745315552, Test Accuracy: 92.91690826416016\n",
            "Epoch 70, Loss: 0.2743416428565979, Accuracy: 93.14334106445312, Test Loss: 0.3575897216796875, Test Accuracy: 92.98517608642578\n",
            "Epoch 71, Loss: 0.27124112844467163, Accuracy: 93.22083282470703, Test Loss: 0.35561931133270264, Test Accuracy: 93.05186462402344\n",
            "Epoch 72, Loss: 0.26820993423461914, Accuracy: 93.29660034179688, Test Loss: 0.35371530055999756, Test Accuracy: 93.11701202392578\n",
            "Epoch 73, Loss: 0.2652457058429718, Accuracy: 93.37068176269531, Test Loss: 0.35188257694244385, Test Accuracy: 93.18079376220703\n",
            "Epoch 74, Loss: 0.2623462975025177, Accuracy: 93.44314575195312, Test Loss: 0.35012444853782654, Test Accuracy: 93.242919921875\n",
            "Epoch 75, Loss: 0.2595095932483673, Accuracy: 93.51404571533203, Test Loss: 0.3484439551830292, Test Accuracy: 93.30366516113281\n",
            "Epoch 76, Loss: 0.25673356652259827, Accuracy: 93.58342742919922, Test Loss: 0.3468359410762787, Test Accuracy: 93.36318969726562\n",
            "Epoch 77, Loss: 0.25401630997657776, Accuracy: 93.6513442993164, Test Loss: 0.345294326543808, Test Accuracy: 93.4214096069336\n",
            "Epoch 78, Loss: 0.25135597586631775, Accuracy: 93.71783447265625, Test Loss: 0.3438105285167694, Test Accuracy: 93.4784927368164\n",
            "Epoch 79, Loss: 0.24875079095363617, Accuracy: 93.78294372558594, Test Loss: 0.3423788547515869, Test Accuracy: 93.53446960449219\n",
            "Epoch 80, Loss: 0.24619904160499573, Accuracy: 93.84671783447266, Test Loss: 0.3409958481788635, Test Accuracy: 93.58926391601562\n",
            "Epoch 81, Loss: 0.2436991184949875, Accuracy: 93.90919494628906, Test Loss: 0.3396560251712799, Test Accuracy: 93.64291381835938\n",
            "Epoch 82, Loss: 0.2412494570016861, Accuracy: 93.97042083740234, Test Loss: 0.33835652470588684, Test Accuracy: 93.69567108154297\n",
            "Epoch 83, Loss: 0.23884855210781097, Accuracy: 94.03042602539062, Test Loss: 0.33709636330604553, Test Accuracy: 93.74734497070312\n",
            "Epoch 84, Loss: 0.23649495840072632, Accuracy: 94.08924865722656, Test Loss: 0.33586668968200684, Test Accuracy: 93.79808044433594\n",
            "Epoch 85, Loss: 0.2341873049736023, Accuracy: 94.14693450927734, Test Loss: 0.3346728980541229, Test Accuracy: 93.84769439697266\n",
            "Epoch 86, Loss: 0.23192425072193146, Accuracy: 94.2034912109375, Test Loss: 0.3335065245628357, Test Accuracy: 93.89633178710938\n",
            "Epoch 87, Loss: 0.22970451414585114, Accuracy: 94.25897216796875, Test Loss: 0.3323734700679779, Test Accuracy: 93.94401550292969\n",
            "Epoch 88, Loss: 0.22752685844898224, Accuracy: 94.31339263916016, Test Loss: 0.3312663435935974, Test Accuracy: 93.99077606201172\n",
            "Epoch 89, Loss: 0.22539010643959045, Accuracy: 94.3667984008789, Test Loss: 0.3301829993724823, Test Accuracy: 94.03672790527344\n",
            "Epoch 90, Loss: 0.22329311072826385, Accuracy: 94.4192123413086, Test Loss: 0.32912954688072205, Test Accuracy: 94.08171081542969\n",
            "Epoch 91, Loss: 0.2212347835302353, Accuracy: 94.47064971923828, Test Loss: 0.3280976712703705, Test Accuracy: 94.12594604492188\n",
            "Epoch 92, Loss: 0.2192140519618988, Accuracy: 94.52115631103516, Test Loss: 0.3270922601222992, Test Accuracy: 94.16925048828125\n",
            "Epoch 93, Loss: 0.2172299027442932, Accuracy: 94.57074737548828, Test Loss: 0.32611119747161865, Test Accuracy: 94.21175384521484\n",
            "Epoch 94, Loss: 0.21528135240077972, Accuracy: 94.61944580078125, Test Loss: 0.3251490294933319, Test Accuracy: 94.25357818603516\n",
            "Epoch 95, Loss: 0.21336744725704193, Accuracy: 94.66728210449219, Test Loss: 0.32420939207077026, Test Accuracy: 94.29463958740234\n",
            "Epoch 96, Loss: 0.211487278342247, Accuracy: 94.71427154541016, Test Loss: 0.323290079832077, Test Accuracy: 94.33495330810547\n",
            "Epoch 97, Loss: 0.20963993668556213, Accuracy: 94.76044464111328, Test Loss: 0.32239097356796265, Test Accuracy: 94.37455749511719\n",
            "Epoch 98, Loss: 0.20782460272312164, Accuracy: 94.80581665039062, Test Loss: 0.32150933146476746, Test Accuracy: 94.4134521484375\n",
            "Epoch 99, Loss: 0.20604044198989868, Accuracy: 94.85041046142578, Test Loss: 0.32064712047576904, Test Accuracy: 94.45166778564453\n",
            "Epoch 100, Loss: 0.20428664982318878, Accuracy: 94.89424133300781, Test Loss: 0.319801390171051, Test Accuracy: 94.48921966552734\n",
            "Epoch 101, Loss: 0.20256245136260986, Accuracy: 94.93733215332031, Test Loss: 0.31897270679473877, Test Accuracy: 94.52611541748047\n",
            "Epoch 102, Loss: 0.20086711645126343, Accuracy: 94.97970581054688, Test Loss: 0.31816038489341736, Test Accuracy: 94.56239318847656\n",
            "Epoch 103, Loss: 0.19919992983341217, Accuracy: 95.02136993408203, Test Loss: 0.31736400723457336, Test Accuracy: 94.5980453491211\n",
            "Epoch 104, Loss: 0.19756019115447998, Accuracy: 95.0623550415039, Test Loss: 0.3165833652019501, Test Accuracy: 94.63311004638672\n",
            "Epoch 105, Loss: 0.19594722986221313, Accuracy: 95.10266876220703, Test Loss: 0.31581762433052063, Test Accuracy: 94.66758728027344\n",
            "Epoch 106, Loss: 0.1943603903055191, Accuracy: 95.14232635498047, Test Loss: 0.3150673806667328, Test Accuracy: 94.70148468017578\n",
            "Epoch 107, Loss: 0.19279904663562775, Accuracy: 95.18135070800781, Test Loss: 0.31433141231536865, Test Accuracy: 94.73483276367188\n",
            "Epoch 108, Loss: 0.19126258790493011, Accuracy: 95.2197494506836, Test Loss: 0.3136093318462372, Test Accuracy: 94.7675552368164\n",
            "Epoch 109, Loss: 0.18975041806697845, Accuracy: 95.2575454711914, Test Loss: 0.31290072202682495, Test Accuracy: 94.79975891113281\n",
            "Epoch 110, Loss: 0.1882619857788086, Accuracy: 95.29474639892578, Test Loss: 0.31220558285713196, Test Accuracy: 94.83135986328125\n",
            "Epoch 111, Loss: 0.18679670989513397, Accuracy: 95.33136749267578, Test Loss: 0.3115229308605194, Test Accuracy: 94.86245727539062\n",
            "Epoch 112, Loss: 0.1853540688753128, Accuracy: 95.36742401123047, Test Loss: 0.31085294485092163, Test Accuracy: 94.89306640625\n",
            "Epoch 113, Loss: 0.1839335411787033, Accuracy: 95.40292358398438, Test Loss: 0.3101949691772461, Test Accuracy: 94.92327880859375\n",
            "Epoch 114, Loss: 0.1825346201658249, Accuracy: 95.4378890991211, Test Loss: 0.30954888463020325, Test Accuracy: 94.9530258178711\n",
            "Epoch 115, Loss: 0.18115682899951935, Accuracy: 95.47232055664062, Test Loss: 0.30891427397727966, Test Accuracy: 94.98230743408203\n",
            "Epoch 116, Loss: 0.17979967594146729, Accuracy: 95.5062484741211, Test Loss: 0.30829057097435, Test Accuracy: 95.010986328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP2hce1Achbe",
        "colab_type": "code",
        "outputId": "a63ba69e-939c-405e-a9ad-ca70db5ecef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = tf.norm(x_train[1], axis=None,keepdims=True)\n",
        "x"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=75855, shape=(1, 1, 1), dtype=float64, numpy=array([[[10.18879151]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy188cnAfX4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clipped = lambda x: tf.maximum(x, 1e-30)\n",
        "#axis_without_batch_size は (1,2,3)となる\n",
        "axis_without_batch_size = (1,2,3)\n",
        "\n",
        "if len(axis_without_batch_size) == 1:\n",
        "    axis_without_batch_size = axis_without_batch_size[0]\n",
        "\n",
        "#normalized = lambda x: x / clipped(tf.norm(x, axis=None))\n",
        "normalized = lambda x: x / clipped(tf.norm(x, axis=None))\n",
        "\n",
        "#plain_softmax = network(input_tensor)\n",
        "perturbation = 1* normalized(tf.random.normal(shape=tf.shape(x_train[1:12]), dtype=tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FtVggdO9dZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6936a02-bd6b-43b3-a312-c92a00a7f554"
      },
      "source": [
        "perturbation[1].shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([28, 28, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTduuTITAAx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95de8027-bfd3-45be-cfde-a05eb6ab2fc2"
      },
      "source": [
        "x"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYN59YBoXjiz",
        "colab_type": "code",
        "outputId": "fd63a03d-e9e3-4ad1-f256-1c1c4a56da7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#tensorboard --logdir content/drive/My Drive/logs/gradient_tape\n",
        "\n",
        "tensorboard --logdir= /content/drive/My Drive/logs/gradient_tape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-73-1710142c159d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    tensorboard --logdir= /content/drive/My Drive/logs/gradient_tape/20190808-084736\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqqa4R2LQ8t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model(x_test)\n",
        "predict1 = tf.argmax(predict,axis=1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSvzkg_zPwU7",
        "colab_type": "code",
        "outputId": "13ad8885-8ebe-455a-da43-0eceaec05248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "x = np.array( [] )\n",
        "count = 0\n",
        "count2 = 0\n",
        "\n",
        "for i in range(len(x_train)+1):\n",
        "    if count % 1000 ==0:\n",
        "        g = x_train[count-1000:count]\n",
        "        predict = model(g)\n",
        "        predict1 = tf.argmax(predict,axis=1).numpy()\n",
        "        x = np.append( x, predict1 )\n",
        "    count+=1\n",
        "    if i ==59999:\n",
        "        print(\"ok\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-d2ccbwRTgi",
        "colab_type": "code",
        "outputId": "c3957d7e-88b5-44ce-f45d-bae539c3e368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "a = 1\n",
        "a.type()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-c5baff9fd0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuMoBwcSlb6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}