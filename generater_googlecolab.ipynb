{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generater_googlecolab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6l_YwYtsSto",
        "colab_type": "code",
        "outputId": "4ce93ee8-afae-4a7a-d7f2-7733a8b4dbc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "#from keras.datasets import cifar10\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Flatten, Dropout,GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import h5py\n",
        "from keras import backend as K\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from keras import metrics\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIDsjlgNssWO",
        "colab_type": "code",
        "outputId": "000a6470-3047-49c3-c2f7-abfa77d08443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9wBw7aEsStz",
        "colab_type": "code",
        "outputId": "92207af2-4081-43a6-b8ec-1255e5bc1729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "source": [
        "input_img = Input(shape=(2048, 2048, 3))\n",
        "x = Conv2D(4, (7, 7), padding='same')(input_img)\n",
        "x = Activation('relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Dropout(0.25)(x)\n",
        "\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(8, (5, 5), padding='same')(x)\n",
        "x = Activation('relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Dropout(0.25)(x)\n",
        "\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "x = Activation('relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Dropout(0.25)(x)\n",
        "\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "#x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "#x = Activation('relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Dropout(0.25)(x)\n",
        "\n",
        "#x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(64, (16,16),padding=\"valid\",strides=16)(x)\n",
        "#x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(3)(x)\n",
        "out = Activation(\"softmax\")(x)\n",
        "model = Model(input_img, out)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "weights_path = '/content/drive/My Drive/research_/weight/best_weight_0507.h5' \n",
        "assert os.path.exists(weights_path), 'Model weights not found '\n",
        "f = h5py.File(weights_path)\n",
        "layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
        "weight_value_tuples = []\n",
        "\n",
        "for k, name in enumerate(layer_names):\n",
        "    if k >= 9:\n",
        "        # 全結合層の重みは読み込まない\n",
        "        break\n",
        "    g = f[name]\n",
        "    weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
        "    if len(weight_names):\n",
        "        weight_values = [g[weight_name] for weight_name in weight_names]\n",
        "        layer = model.layers[k]\n",
        "        symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n",
        "        if len(weight_values) != len(symbolic_weights):\n",
        "            raise Exception('Layer #' + str(k) +\n",
        "                            ' (named \"' + layer.name +\n",
        "                            '\" in the current model) was found to '\n",
        "                            'correspond to layer ' + name +\n",
        "                            ' in the save file. '\n",
        "                            'However the new layer ' + layer.name +\n",
        "                            ' expects ' + str(len(symbolic_weights)) +\n",
        "                            ' weights, but the saved weights have ' +\n",
        "                            str(len(weight_values)) +' elements.')\n",
        "        weight_value_tuples += zip(symbolic_weights, weight_values)\n",
        "K.batch_set_value(weight_value_tuples)\n",
        "f.close()\n",
        "print('Model loaded.')\n",
        "\n",
        "#for layer in model.layers[:9]:\n",
        "        #layer.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 2048, 2048, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 2048, 2048, 4)     592       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2048, 2048, 4)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1024, 1024, 4)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1024, 1024, 8)     808       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1024, 1024, 8)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 512, 512, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 512, 512, 16)      1168      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 512, 512, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 256, 256, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        262208    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                1048640   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 1,313,611\n",
            "Trainable params: 1,313,611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdoEDLnebkdW",
        "colab_type": "code",
        "outputId": "dac45b77-bfc4-4218-9134-c89b00bda5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "input_img = Input(shape=(2048, 2048, 3))\n",
        "x = Conv2D(4, (7, 7), padding='same')(input_img)\n",
        "x = Activation('relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Dropout(0.25)(x)\n",
        "\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(8, (5, 5), padding='same')(x)\n",
        "x = Activation('relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Dropout(0.25)(x)\n",
        "\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "x = Activation('relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Dropout(0.25)(x)\n",
        "\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "#x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "#x = Activation('relu')(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Dropout(0.25)(x)\n",
        "\n",
        "#x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(512, (16,16),padding=\"valid\",strides=16)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "#x = Flatten()(x)\n",
        "#x = Dense(128)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(3)(x)\n",
        "out = Activation(\"softmax\")(x)\n",
        "model = Model(input_img, out)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 2048, 2048, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 2048, 2048, 4)     592       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2048, 2048, 4)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1024, 1024, 4)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1024, 1024, 8)     808       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1024, 1024, 8)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 512, 512, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 512, 512, 16)      1168      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 512, 512, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 256, 256, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 512)       2097664   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1539      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 2,101,771\n",
            "Trainable params: 2,101,771\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztbb55KZsSt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelCheckpoint = ModelCheckpoint(filepath =\"/content/drive/My Drive/research_/weight/weight_0529_03.h5\",\n",
        "                                  monitor = \"val_loss\",\n",
        "                                  verbose=1,\n",
        "                                  save_best_only = True,\n",
        "                                  save_weights_only = False,\n",
        "                                  mode = \"min\",\n",
        "                                  period =1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrvSwpPjsSuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataGenerator(object):\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.images = []\n",
        "    self.labels = []\n",
        "    self.labelsx = []\n",
        "  #file_pathはメタCSVでーたのこと\n",
        "  \n",
        "  def flow_from_directory(self, file_path, classes, batch_size=4):\n",
        "    blunc=np.empty((batch_size, 2048, 2048, 3), np.float32)\n",
        "    blunc_l=np.empty((batch_size), np.float32)\n",
        "    # LabelEncode(classをint型に変換)するためのdict\\n\",\n",
        "    classes = {v: i for i, v in enumerate(sorted(classes))}\n",
        "    file_path = pd.read_csv(file_path)\n",
        "    boss_dir = \"/mnt/Doc\"\n",
        "    while True:\n",
        "      # ディレクトリから画像のパスを取り出す\n",
        "      count = 0\n",
        "      count = 0\n",
        "      bin8 = np.arange(batch_size,length,batch_size)\n",
        "      hoge = np.arange(length)\n",
        "      #np.random.shuffle(hoge)\n",
        "      batch10 = np.split(hoge, bin8)\n",
        "      #print(len(batch10))\n",
        "      for ic, bbb in enumerate(batch10):\n",
        "      for i in range(len(file_path)):\n",
        "        # 画像を読み込みRGBへの変換、Numpyへの変換を行い、配列(self.iamges)に格納\n",
        "        path = file_path.loc[i][\"path1\"]\n",
        "        print(i)\n",
        "        with Image.open(path) as f:\n",
        "          self.images.append((np.asarray(f.convert('RGB'), dtype=np.float32))/255)\n",
        "          # ファイル名からラベルを取り出し、配列(self.labels)に格納\n",
        "          #_, y = path.stem.split('_')\n",
        "        label = file_path.loc[i][\"type\"]\n",
        "        self.labels.append(to_categorical(classes[label],len(classes)))\n",
        "        self.labelsx.append(to_categorical(classes[label],len(classes)))\n",
        "          # ここまでを繰り返し行い、batch_sizeの数だけ配列(self.iamges, self.labels)に格納\n",
        "          # batch_sizeの数だけ格納されたら、戻り値として返し、配列(self.iamges, self.labels)を空にする\n",
        "        if len(self.images)== batch_size:\n",
        "          #print(len(self.images))\n",
        "          inputs = np.asarray(self.images,dtype=np.float32) \n",
        "          targets = np.asarray(self.labels,dtype=np.float32)\n",
        "            #print(len(self.images))\n",
        "          count+=1\n",
        "            #if count%1000==0:\n",
        "            #print(\"n*1000!\")\n",
        "          self.reset()\n",
        "          yield inputs, targets\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0VZYglKYEeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataGenerator3(object):\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.images = []\n",
        "    self.labels = []\n",
        "    self.labelsx = []\n",
        "  #file_pathはメタCSVでーたのこと\n",
        "  \n",
        "  def flow_from_directory(self, file_path, classes, batch_size=4):\n",
        "    blunc=np.empty((batch_size, 2048, 2048, 3), np.float32)\n",
        "    blunc_l=np.empty((batch_size), np.float32)\n",
        "    # LabelEncode(classをint型に変換)するためのdict\\n\",\n",
        "    classes = {v: i for i, v in enumerate(sorted(classes))}\n",
        "    file_path = pd.read_csv(file_path)\n",
        "    boss_dir = \"/mnt/Doc\"\n",
        "    while True:\n",
        "      # ディレクトリから画像のパスを取り出す\n",
        "      count = 0\n",
        "      bin8 = np.arange(batch_size,length,batch_size)\n",
        "      hoge = np.arange(length)\n",
        "      #np.random.shuffle(hoge)\n",
        "      batch10 = np.split(hoge, bin8)\n",
        "      #print(len(batch10))\n",
        "      for ic, bbb in enumerate(batch10):\n",
        "      for i in range(len(file_path)):\n",
        "        # 画像を読み込みRGBへの変換、Numpyへの変換を行い、配列(self.iamges)に格納\n",
        "        path = file_path.loc[i][\"path1\"]\n",
        "        print(i)\n",
        "        with Image.open(path) as f:\n",
        "          self.images.append((np.asarray(f.convert('RGB'), dtype=np.float32))/255)\n",
        "          # ファイル名からラベルを取り出し、配列(self.labels)に格納\n",
        "          #_, y = path.stem.split('_')\n",
        "        label = file_path.loc[i][\"type\"]\n",
        "        self.labels.append(to_categorical(classes[label],len(classes)))\n",
        "        self.labelsx.append(to_categorical(classes[label],len(classes)))\n",
        "          # ここまでを繰り返し行い、batch_sizeの数だけ配列(self.iamges, self.labels)に格納\n",
        "          # batch_sizeの数だけ格納されたら、戻り値として返し、配列(self.iamges, self.labels)を空にする\n",
        "        if len(self.images)== batch_size:\n",
        "          #print(len(self.images))\n",
        "          inputs = np.asarray(self.images,dtype=np.float32) \n",
        "          targets = np.asarray(self.labels,dtype=np.float32)\n",
        "            #print(len(self.images))\n",
        "          count+=1\n",
        "            #if count%1000==0:\n",
        "            #print(\"n*1000!\")\n",
        "          self.reset()\n",
        "          yield inputs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C1O1HaA1hUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataGenerator1(object):\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "  def reset(self):\n",
        "    self.images = []\n",
        "    self.labels = []\n",
        "  def flow_from_directory(self, file_path, classes, batch_size=8):\n",
        "    # LabelEncode(classをint型に変換)するためのdict\\n\",\n",
        "    classes = {v: i for i, v in enumerate(sorted(classes))}\n",
        "    file_path1 = pd.read_csv(file_path)\n",
        "    length = len(file_path1)\n",
        "    while True:\n",
        "      # ディレクトリから画像のパスを取り出すcount = 0\n",
        "      count = 0\n",
        "      bin8 = np.arange(batch_size,length,batch_size)\n",
        "      hoge = np.arange(length)\n",
        "      #np.random.shuffle(hoge)\n",
        "      batch10 = np.split(hoge, bin8)\n",
        "      #print(len(batch10))\n",
        "      for ic, bbb in enumerate(batch10):\n",
        "        print(bbb)\n",
        "        #print(str(ic),\"回目です\")\n",
        "        count = 0\n",
        "        for ib,bb in enumerate(bbb):\n",
        "          path = file_path1.loc[ib][\"path1\"]\n",
        "          with Image.open(path) as f:\n",
        "            self.images.append((np.asarray(f.convert('RGB'), dtype=np.float32))/255)\n",
        "          # ファイル名からラベルを取り出し、配列(self.labels)に格納\n",
        "          #_, y = path.stem.split('_')\n",
        "          label = file_path1.loc[ib][\"type\"]\n",
        "          self.labels.append(to_categorical(classes[label],len(classes)))\n",
        "          #self.labelsx.append(to_categorical(classes[label],len(classes)))\n",
        "            #print(ib)\n",
        "          if len(self.labels)== batch_size:\n",
        "            #print(len(self.images))\n",
        "            inputs = np.asarray(self.images,dtype=np.float32) \n",
        "            targets = np.asarray(self.labels,dtype=np.float32)\n",
        "            print(targets)\n",
        "            #print(len(self.images))\n",
        "            #if count%1000==0:\n",
        "            #print(\"n*1000!\")\n",
        "            self.reset()\n",
        "            yield inputs, targets\n",
        "      \n",
        "                    \n",
        "              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cERte_CRuvWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataGenerator2(object):\n",
        "    def __init__(self):\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        #file_pathはメタCSVでーたのこと\n",
        "\n",
        "    def flow_from_directory(self, file_path, classes, batch_size=16):\n",
        "        tmp_images = np.zeros((batch_size, 2048, 2048, 3))\n",
        "        tmp_labels = np.zeros((batch_size, 3))\n",
        "\n",
        "        # LabelEncode(classをint型に変換)するためのdict\\n\",\n",
        "        classes = {v: i for i, v in enumerate(sorted(classes))}\n",
        "        file_path1 = pd.read_csv(file_path)\n",
        "        length = len(file_path1)\n",
        "        while True:\n",
        "            # ディレクトリから画像のパスを取り出すcount = 0\n",
        "            count = 0\n",
        "            bin8 = np.arange(batch_size,length,batch_size)\n",
        "            hoge = np.arange(length)\n",
        "            np.random.shuffle(hoge)\n",
        "            batch10 = np.split(hoge, bin8)\n",
        "            #print(len(batch10))\n",
        "            for ic, bbb in enumerate(batch10):\n",
        "                #print(bbb)\n",
        "                #print(str(ic),\"回目です\")\n",
        "                for ib,bb in enumerate(bbb):\n",
        "                    #print(ib, bb)\n",
        "                    #print(bb)\n",
        "                    path = file_path1.loc[bb][\"path1\"]\n",
        "                    with Image.open(path) as f:\n",
        "                        tmp_images[ib] = np.asarray(f, dtype=np.float32)/255\n",
        "                    label = file_path1.loc[bb][\"type\"]\n",
        "                    tmp_labels[ib] = to_categorical(classes[label],len(classes))\n",
        "                #print(tmp_labels, np.mean(tmp_images, axis=(1,2,3)))\n",
        "                yield tmp_images, tmp_labels\n",
        "      #validation_data=test_datagen.flow_from_directory(test_dir, classes),\n",
        "    #validation_steps=104/batchsize,\n",
        "    #callbacks = [modelCheckpoint]             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjHF2DiQl5D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataGenerator1(object):\n",
        "    def __init__(self):\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        #file_pathはメタCSVでーたのこと\n",
        "\n",
        "    def flow_from_directory(self, file_path, classes, batch_size=8):\n",
        "        tmp_images = np.zeros((batch_size, 2048, 2048, 3))\n",
        "        tmp_labels = np.zeros((batch_size, 3))\n",
        "\n",
        "        # LabelEncode(classをint型に変換)するためのdict\\n\",\n",
        "        classes = {v: i for i, v in enumerate(sorted(classes))}\n",
        "        file_path1 = pd.read_csv(file_path)\n",
        "        length = len(file_path1)\n",
        "        while True:\n",
        "            # ディレクトリから画像のパスを取り出すcount = 0\n",
        "            count = 0\n",
        "            bin8 = np.arange(batch_size,length,batch_size)\n",
        "            hoge = np.arange(length)\n",
        "            np.random.shuffle(hoge)\n",
        "            batch10 = np.split(hoge, bin8)\n",
        "            #print(len(batch10))\n",
        "            for ic, bbb in enumerate(batch10):\n",
        "                #print(bbb)\n",
        "                #print(str(ic),\"回目です\")\n",
        "                for ib,bb in enumerate(bbb):\n",
        "                    #print(ib, bb)\n",
        "                    #print(bb)\n",
        "                    path = file_path1.loc[bb][\"path1\"]\n",
        "                    with Image.open(path) as f:\n",
        "                        tmp_images[ib] = np.asarray(f, dtype=np.float32)/255\n",
        "                    label = file_path1.loc[bb][\"type\"]\n",
        "                    tmp_labels[ib] = to_categorical(classes[label],len(classes))\n",
        "                #print(tmp_labels, np.mean(tmp_images, axis=(1,2,3)))\n",
        "                yield tmp_images, tmp_labels\n",
        "      #validation_data=test_datagen.flow_from_directory(test_dir, classes),\n",
        "    #validation_steps=104/batchsize,\n",
        "    #callbacks = [modelCheckpoint]             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWaUxsZCsSuO",
        "colab_type": "code",
        "outputId": "f40c2cd1-536f-4ff2-f179-2ebd573855f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#test_dir = pathlib.Path('/path/to/test/')\n",
        "#x = pd.read_csv(\"/mnt/Doc/2048pix_tissue_all/RGBmean<190.csv\")\n",
        "train_dir = \"/content/drive/My Drive/train_7136.csv\"\n",
        "test_dir = \"/content/drive/My Drive/val_104.csv\"\n",
        "train_len = len(pd.read_csv(train_dir))\n",
        "#print(train_len)\n",
        "test_len = len(pd.read_csv(test_dir))\n",
        "test_datagen = ImageDataGenerator1()\n",
        "train_datagen = ImageDataGenerator2()\n",
        "classes =[\"PI\",\"PP\",\"TRU\"]\n",
        "batchsize_train = 16\n",
        "batchsize_val = 8\n",
        "model.fit_generator(\n",
        "    generator=train_datagen.flow_from_directory(train_dir, classes),\n",
        "    steps_per_epoch=7136/batchsize_train,\n",
        "    epochs=1000,\n",
        "    verbose=1,\n",
        "    callbacks = [modelCheckpoint] ,\n",
        "    validation_data=test_datagen.flow_from_directory(test_dir, classes),\n",
        "    validation_steps=104/batchsize_val\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1000\n",
            "147/446 [========>.....................] - ETA: 35:52 - loss: 1.3687 - acc: 0.3520"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9J5Ba6xBmwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data=test_datagen.flow_from_directory(test_dir, classes),\n",
        "    validation_steps=104/batchsize,\n",
        "    callbacks = [modelCheckpoint] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN-ZrpuvsSuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/research_/weight/weight_0529_02.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDd9hb_t35Qo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKon-GAJsSuc",
        "colab_type": "code",
        "outputId": "696ea98e-a581-422b-8922-6924042a5f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "test_dir = \"/content/drive/My Drive/val_104.csv\"\n",
        "test_datagen = ImageDataGenerator1()\n",
        "classes =[\"PI\",\"PP\",\"TRU\"]\n",
        "batchsize = 8\n",
        "predict = model.evaluate_generator(test_datagen.flow_from_directory(test_dir,classes),\n",
        "                                   steps=104/batchsize,\n",
        "                                   verbose=1\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[66 92 78 60 44  7 95 31]\n",
            "[57 51 70 61 99 84 96 77]\n",
            " 1/13 [=>............................] - ETA: 16s[69 85 35 19 26 23 16 76]\n",
            " 2/13 [===>..........................] - ETA: 12s[64  0 45  4 52 75 86  9]\n",
            " 3/13 [=====>........................] - ETA: 10s[ 34  25  46 100  68  11  94  37]\n",
            " 4/13 [========>.....................] - ETA: 9s [93 73 83 71 33 10 13 15]\n",
            " 5/13 [==========>...................] - ETA: 8s[17 72 36 81 20 29 88 65]\n",
            " 6/13 [============>.................] - ETA: 7s[102   5  42  48  38  89  32  97]\n",
            " 7/13 [===============>..............] - ETA: 6s[80  8 41 58 12  2 28 91]\n",
            " 8/13 [=================>............] - ETA: 5s[55 39 82 27 24 74 50 79]\n",
            " 9/13 [===================>..........] - ETA: 4s[ 90  98   6  22 101  49  62  56]\n",
            "10/13 [======================>.......] - ETA: 3s[87 47  1 43 54 59 14 30]\n",
            "11/13 [========================>.....] - ETA: 1s[ 53  21  40   3  18  63  67 103]\n",
            "12/13 [==========================>...] - ETA: 0s[ 49   1 101  99  10  17  22  45]\n",
            "13/13 [==============================] - 13s 992ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu0qe4FasSut",
        "colab_type": "code",
        "outputId": "db5f58a8-3886-4f50-8288-2ece1b453531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.6657338569057174e-06, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8GncZFM30O6",
        "colab_type": "code",
        "outputId": "20b94e99-2034-4031-c293-d4890097d333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "test_dir = \"/content/drive/My Drive/val_104.csv\"\n",
        "test_datagen = ImageDataGenerator1()\n",
        "classes =[\"PI\",\"PP\",\"TRU\"]\n",
        "batchsize = 8\n",
        "predict = model.predict_generator(test_datagen.flow_from_directory(test_dir,classes),\n",
        "                                   steps=104/batchsize,\n",
        "                                   verbose=1\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7]\n",
            "[ 8  9 10 11 12 13 14 15]\n",
            " 1/13 [=>............................] - ETA: 18s[16 17 18 19 20 21 22 23]\n",
            " 2/13 [===>..........................] - ETA: 13s[24 25 26 27 28 29 30 31]\n",
            " 3/13 [=====>........................] - ETA: 11s[32 33 34 35 36 37 38 39]\n",
            " 4/13 [========>.....................] - ETA: 10s[40 41 42 43 44 45 46 47]\n",
            " 5/13 [==========>...................] - ETA: 8s [48 49 50 51 52 53 54 55]\n",
            " 6/13 [============>.................] - ETA: 7s[56 57 58 59 60 61 62 63]\n",
            " 7/13 [===============>..............] - ETA: 6s[64 65 66 67 68 69 70 71]\n",
            " 8/13 [=================>............] - ETA: 5s[72 73 74 75 76 77 78 79]\n",
            " 9/13 [===================>..........] - ETA: 4s[80 81 82 83 84 85 86 87]\n",
            "10/13 [======================>.......] - ETA: 3s[88 89 90 91 92 93 94 95]\n",
            "11/13 [========================>.....] - ETA: 2s[ 96  97  98  99 100 101 102 103]\n",
            "12/13 [==========================>...] - ETA: 1s[0 1 2 3 4 5 6 7]\n",
            "13/13 [==============================] - 13s 1s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE7xgB31A8Fe",
        "colab_type": "code",
        "outputId": "c1f3e4eb-2bbd-4177-b8bf-e7b99aef53da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict[3].argmax()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9gCrvUKBORZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = []\n",
        "classes =[\"PI\",\"PP\",\"TRU\"]\n",
        "classes = {v: i for i, v in enumerate(sorted(classes))}\n",
        "for i in range(len(predict)):\n",
        "  if predict[i].argmax() == 0:\n",
        "    x.append(\"PI\")\n",
        "  if predict[i].argmax() == 1:\n",
        "    x.append(\"PP\")\n",
        "  if predict[i].argmax() == 2:\n",
        "    x.append(\"TRU\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVxG0saQDbVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes =[\"PI\",\"PP\",\"TRU\"]\n",
        "classes = {v: i for i, v in enumerate(sorted(classes))}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLf8G-8ED67n",
        "colab_type": "code",
        "outputId": "973814cb-99a7-4b1b-ff6b-99c6dae31dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PI': 0, 'PP': 1, 'TRU': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3VgRd_zDl51",
        "colab_type": "code",
        "outputId": "f34af853-f3f4-4c45-c79f-3d482047e10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'PI', 1: 'PP', 2: 'TRU'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2mRReHoEZgR",
        "colab_type": "code",
        "outputId": "f301b497-d6e4-46c8-86bd-ee2542a79272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "y = pd.read_csv(\"/content/drive/My Drive/val_104.csv\",sep=',')\n",
        "print(y[\"type\"].head(20))\n",
        "print(y.loc[21])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      PI\n",
            "1      PP\n",
            "2      PP\n",
            "3      PI\n",
            "4      PP\n",
            "5      PP\n",
            "6      PI\n",
            "7     TRU\n",
            "8      PP\n",
            "9      PI\n",
            "10     PP\n",
            "11     PI\n",
            "12     PP\n",
            "13     PI\n",
            "14     PI\n",
            "15    TRU\n",
            "16     PP\n",
            "17     PI\n",
            "18     PI\n",
            "19     PI\n",
            "Name: type, dtype: object\n",
            "Unnamed: 0                                                   21\n",
            "type                                                         PI\n",
            "ID                                      TCGA-97-7554-01A-01-BS1\n",
            "file_pass     /home/kanayalab/Documents/2048pix tissue all/P...\n",
            "Split                                                      test\n",
            "high                                                       2048\n",
            "wide                                                       2048\n",
            "depth                                                         3\n",
            "sd                                                      49.6476\n",
            "RGBmean                                                 181.468\n",
            "path1         /content/drive/My Drive/2048pix_tissue_choice/...\n",
            "Name: 21, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YQuSLMMC4lf",
        "colab_type": "code",
        "outputId": "eb71783e-8c6c-4828-cb6c-bf880094642b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x[21]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PP'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6ySJE5sDBLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}