{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.load(\"/mnt/Doc/reserch/train.npy\")\n",
    "test=np.load(\"/mnt/Doc/reserch/test.npy\")\n",
    "x_train = train.astype('float32')\n",
    "x_test = test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (9000, 128, 128, 3)\n",
      "9000 train samples\n",
      "1500 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide x_test into validation and test\n",
    "x_val = x_test[:1200]\n",
    "x_test = x_test[1200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data: (1200, 128, 128, 3) \n",
      "test data: (300, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"validation data: {0} \\ntest data: {1}\".format(x_val.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(128, 128, 3))\n",
    "x = Conv2D(64, (3, 3), padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(16, (3, 3), padding='same')(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(3, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "decoded = Activation('sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_img, decoded)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1200 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 77s 9ms/step - loss: 0.5836 - val_loss: 0.5754\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.5530 - val_loss: 0.5543\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.5358 - val_loss: 0.5407\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.5233 - val_loss: 0.5346\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.5138 - val_loss: 0.5133\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.5067 - val_loss: 0.5050\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.5017 - val_loss: 0.4953\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4976 - val_loss: 0.4922\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4949 - val_loss: 0.4897\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4928 - val_loss: 0.4875\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4913 - val_loss: 0.4876\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4900 - val_loss: 0.4855\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4894 - val_loss: 0.4848\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4887 - val_loss: 0.4850\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4885 - val_loss: 0.4861\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4882 - val_loss: 0.4843\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4877 - val_loss: 0.4838\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4875 - val_loss: 0.4836\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4874 - val_loss: 0.4837\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4873 - val_loss: 0.4837\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4872 - val_loss: 0.4859\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4871 - val_loss: 0.4832\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4867 - val_loss: 0.4833\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4868 - val_loss: 0.4827\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4869 - val_loss: 0.4836\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4867 - val_loss: 0.4840\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4867 - val_loss: 0.4826\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4865 - val_loss: 0.4827\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4867 - val_loss: 0.4827\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4864 - val_loss: 0.4832\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4862 - val_loss: 0.4829\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4862 - val_loss: 0.4824\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4863 - val_loss: 0.4828\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4864 - val_loss: 0.4821\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4860 - val_loss: 0.4831\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4861 - val_loss: 0.4824\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4859 - val_loss: 0.4819\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4862 - val_loss: 0.4840\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4859 - val_loss: 0.4823\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4859 - val_loss: 0.4822\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4860 - val_loss: 0.4825\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4860 - val_loss: 0.4819\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4858 - val_loss: 0.4819\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4857 - val_loss: 0.4823\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4857 - val_loss: 0.4817\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4859 - val_loss: 0.4818\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4856 - val_loss: 0.4826\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4857 - val_loss: 0.4834\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4856 - val_loss: 0.4823\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4856 - val_loss: 0.4825\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4857 - val_loss: 0.4816\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4856 - val_loss: 0.4822\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4854 - val_loss: 0.4820\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4858 - val_loss: 0.4816\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4854 - val_loss: 0.4816\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4854 - val_loss: 0.4816\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4817\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4816\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4854 - val_loss: 0.4816\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4814\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4815\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4854 - val_loss: 0.4814\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4815\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4852 - val_loss: 0.4815\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4852 - val_loss: 0.4827\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4825\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4816\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4854 - val_loss: 0.4819\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4852 - val_loss: 0.4817\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4816\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4852 - val_loss: 0.4818\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4820\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4852 - val_loss: 0.4813\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4850 - val_loss: 0.4812\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4851 - val_loss: 0.4813\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4850 - val_loss: 0.4812\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4851 - val_loss: 0.4814\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4853 - val_loss: 0.4816\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4850 - val_loss: 0.4811\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4852 - val_loss: 0.4817\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4852 - val_loss: 0.4824\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4850 - val_loss: 0.4810\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4851 - val_loss: 0.4816\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4851 - val_loss: 0.4812\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4851 - val_loss: 0.4813\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4848 - val_loss: 0.4819\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4850 - val_loss: 0.4817\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4850 - val_loss: 0.4819\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 71s 8ms/step - loss: 0.4849 - val_loss: 0.4810\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4849 - val_loss: 0.4813\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4850 - val_loss: 0.4816\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4849 - val_loss: 0.4817\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4848 - val_loss: 0.4811\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4850 - val_loss: 0.4810\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4848 - val_loss: 0.4812\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4849 - val_loss: 0.4808\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4848 - val_loss: 0.4818\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4848 - val_loss: 0.4808\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4848 - val_loss: 0.4808\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.4849 - val_loss: 0.4818\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, x_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, x_val),\n",
    "                    shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
