{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMSAT_mnsit.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazuki-de/git_reserch_code/blob/master/IMSAT_mnsit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZF0xNLHyAw-",
        "colab_type": "code",
        "outputId": "66c51eca-02d4-4ee4-d239-2cc0e8aab50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation , Softmax, MaxPool2D,UpSampling2D, Input\n",
        "from tensorflow.keras import Model\n",
        "import datetime\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 348.9MB 100kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 49.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 46.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3EGpbKQyI-u",
        "colab_type": "code",
        "outputId": "186582a8-012e-445e-8173-c4f48f1ae7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNRCFB4gyP-G",
        "colab_type": "code",
        "outputId": "0418548b-c14b-4b36-f0ec-c7e4599b2d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd  /content/drive/My Drive/logs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X89NCoRJyQtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/content/drive/My Drive/logs/gradient_tape\", histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNk17qRXbK5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ead3816b-bbf2-476c-e869-d74c457d0fa0"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(100)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(100)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE-y47XiGn06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INput = Input(shape=(28,28,1))\n",
        "x = Conv2D(32,(3,3),padding=\"same\", activation='relu')(INput)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "out = Dense(10)(x)\n",
        "model1 = Model(INput,out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdAPsKsftqUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = Conv2D(32,(3,3),padding=\"same\", activation='relu')\n",
        "        self.maxpool = MaxPool2D((2, 2), padding='same')\n",
        "        self.conv2 = Conv2D(16,(3,3),padding=\"same\", activation='relu')\n",
        "        self.maxpool2 = MaxPool2D((2, 2), padding='same')\n",
        "        self.conv3 = Conv2D(16,(3,3),padding=\"same\", activation='relu')\n",
        "        self.maxpoo3 = MaxPool2D((2, 2), padding='same')\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation='relu')\n",
        "        self.d2 = Dense(10)\n",
        "        \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.flatten(x)\n",
        "        x =self.d1(x)\n",
        "        return self.d2(x)\n",
        "\n",
        "\n",
        "model1 = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdDBcUNq0yCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence(q_logi, p_logi):\n",
        "    q_logit = Activation(\"softmax\")(q_logi)\n",
        "    p_logit = Activation(\"softmax\")(p_logi)\n",
        "    qlogq = tf.reduce_sum(q_logit * tf.math.log(q_logit), axis=1)\n",
        "    qlogp = tf.reduce_sum(q_logit * tf.math.log(p_logit), axis=1)\n",
        "    return qlogq - qlogp\n",
        "def get_unit_vector(v):\n",
        "    return  v / (tf.sqrt(tf.reduce_sum(v ** 2, axis=None,keepdims=True) + 1e-16))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmenScDRzq_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VAT_KL(input_tensor, be_softmax, xi=10, epsilon=1.0, weight=1.0, num_approximation=1, clip_value_min=1e-16, dtype=tf.float64):\n",
        "    \n",
        "    #配列内の数値の最大値が第二変数になるように置き換える\n",
        "    #clipped = lambda x: tf.maximum(x, clip_value_min)\n",
        "    #axis_without_batch_size は (1,2,3)となる\n",
        "    #axis_without_batch_size = tuple(range(1,len(input_tensor.get_shape())))\n",
        "    \n",
        "    #if len(axis_without_batch_size) == 1:\n",
        "    #    axis_without_batch_size = axis_without_batch_size[0]\n",
        "        \n",
        "    #normalized = lambda x: x / clipped(tf.norm(x, axis=None))\n",
        "    #normalized = lambda x: x / clipped(tf.norm(x, axis=None,keepdims=True))\n",
        "    #normalized = lambda x: x / tf.norm(x, axis=None,keepdims=True)\n",
        "    #plain_softmax = network(input_tensor)\n",
        "    \n",
        "    #noplain_softmax = Activation(\"softmax\")(plain_softmax)\n",
        "    \n",
        "    #適当な単位ベクトルにxi=10を掛けた数:pertubationの作成\n",
        "    perturbation = xi * get_unit_vector(tf.random.normal(shape=tf.shape(input_tensor), dtype=dtype))\n",
        "    #print(perturbation.numpy())\n",
        "    \n",
        "    for i in range(num_approximation):\n",
        "        \n",
        "        softmax_accommodating_perturbation = model1(input_tensor+perturbation)\n",
        "        \n",
        "        #softmax_accommodating_perturbation_af = Activation(\"softmax\")(softmax_accommodating_perturbation)\n",
        "        # ノイズを足した配列とノーマルな配列がCNNで出力された結果のKL距離を求める\n",
        "        dist = tf.reduce_mean(kl_divergence(be_softmax,softmax_accommodating_perturbation))\n",
        "        #cross_entropy_accommodating_perturbation = -tf.reduce_sum(plain_softmax * tf.math.log(clipped(softmax_accommodating_perturbation))) * weight\n",
        "        adversarial_direction = tf.gradients(dist, [perturbation])[0]\n",
        "        pertubation = tf.stop_gradient(adversarial_direction)\n",
        "    #print(\"ok\")    \n",
        "    \n",
        "    pertubation = epsilon * get_unit_vector(pertubation)\n",
        "    \n",
        "    #corrent_softmax = model1(input_tensor) \n",
        "    vat_softmax = model1(input_tensor + perturbation)\n",
        "    loss =  tf.reduce_mean(kl_divergence(be_softmax,vat_softmax))\n",
        "    return  loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fdnl19iDr7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_entropy(p):\n",
        "    return - tf.reduce_sum(p*tf.math.log(p+1e-16),axis = 1)\n",
        "\n",
        "def compute_marginal_entropy(p_batch):\n",
        "    return  compute_entropy(tf.reduce_mean(p_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qne_U9p5auUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#損失関数\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "#最適化手法\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "#評価関数\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_loss1 = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_loss2 = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2b7AlZVoXDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ミニバッチ学習==1epocでn枚の画像からx枚ずつ取り出しn/x回学習する(重みを更新していく)手法\n",
        "#バッチ学習 == 1epocでn枚の画像から1枚ずつ取り出しn回学習する（重みを更新していく）手法\n",
        "#オンライン学習 ==1epocでn枚の画像からn枚全てを用い学習する(重みを更新していく)手法　#メモリ消費大\n",
        "@tf.function\n",
        "def train_step(image,label,batch_size):\n",
        "    with tf.GradientTape() as tape:\n",
        "        p = Activation('softmax')(model1(image))\n",
        "        p_ave = tf.reduce_mean(p,axis=0)\n",
        "        loss_eq2 = -tf.reduce_sum(p_ave * tf.math.log(p_ave + 1e-16))\n",
        "        loss_eq1 = tf.reduce_mean(compute_entropy(p))\n",
        "        loss_eq = loss_eq1 - 4* loss_eq2\n",
        "        #with tf.variable_scope(tf.get_variable_scope(),reuse=True):\n",
        "        #logit = model1(image)\n",
        "        \n",
        "        #---------------------------------------------------------------------------------\n",
        "        plain_softmax = model1(image)\n",
        "        \n",
        "        noplain_softmax = Activation(\"softmax\")(plain_softmax)\n",
        "\n",
        "        #適当な単位ベクトルにxi=10を掛けた数:pertubationの作成\n",
        "        perturbation = 10 * get_unit_vector(tf.random.normal(shape=tf.shape(image), dtype=tf.float32))\n",
        "        #print(perturbation.numpy())\n",
        "        for i in range(1):\n",
        "            softmax_accommodating_perturbation = model1(image+perturbation)\n",
        "            softmax_accommodating_perturbation_af = Activation(\"softmax\")(softmax_accommodating_perturbation)\n",
        "            # ノイズを足した配列とノーマルな配列がCNNで出力された結果のKL距離を求める\n",
        "            dist = kl_divergence(noplain_softmax,softmax_accommodating_perturbation_af)\n",
        "            #cross_entropy_accommodating_perturbation = -tf.reduce_sum(plain_softmax * tf.math.log(clipped(softmax_accommodating_perturbation))) * weight\n",
        "            adversarial_direction = tf.gradients(dist, [perturbation])[0]\n",
        "            print(adversarial_direction)\n",
        "            pertubation = tf.stop_gradient(adversarial_direction)\n",
        "        #print(\"ok\")    \n",
        "\n",
        "        pertubation = 1 * get_unit_vector(adversarial_direction)\n",
        "        corrent_softmax = Activation('softmax')(model1(image)) \n",
        "        vat_softmax = Activation('softmax')(model1(image + perturbation))\n",
        "        VAT_loss = kl_divergence(corrent_softmax,vat_softmax)\n",
        "        #---------------------------------------------------------------------------------------------\n",
        "        \n",
        "        total_loss = VAT_loss +0.2 * loss_eq\n",
        "        #hy_ = compute_entropy(p)\n",
        "        #p_ave = tf.reduce_mean(p,axis=0)\n",
        "        #hy_x = -tf.reduce_sum(p_ave*tf.math.log(p_ave+1e-16))\n",
        "        #print(hy)\n",
        "        #hy_x = tf.reduce_sum(compute_entropy(p))/batch_size\n",
        "        #print(hy_x)\n",
        "        #Rsut = -tf.reduce_sum(VAT_KL(image,model1))/batch_size\n",
        "        #print(Rsut)\n",
        "        #loss = Rsut - 0.2*((4)*hy-hy_x)\n",
        "    gradients = tape.gradient(total_loss, model1.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model1.trainable_variables))\n",
        "    \n",
        "    train_loss(total_loss)\n",
        "    #train_loss1(Rsut)\n",
        "    #train_loss2(0.2*((4.0)*hy-hy_x))\n",
        "    #train_loss(loss)\n",
        "    #train_loss\n",
        "    \n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uXj-nnVgv8S",
        "colab_type": "code",
        "outputId": "ef476093-4ba7-4aec-c633-3e9c7b134619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pip install munkres\n",
        "from munkres import Munkres, print_matrix"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: munkres in /usr/local/lib/python3.6/dist-packages (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLc0Gss0ZwKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(y_pred, y_t,tot_cl=10):\n",
        "    # compute the accuracy using Hungarian algorithm\n",
        "    m = Munkres()\n",
        "    mat = np.zeros((tot_cl, tot_cl))\n",
        "    for i in range(tot_cl):\n",
        "        for j in range(tot_cl):\n",
        "            mat[i][j] = np.sum(np.logical_and(y_pred == i, y_t == j))\n",
        "    indexes = m.compute(-mat)\n",
        "\n",
        "    corresp = []\n",
        "    for i in range(tot_cl):\n",
        "        corresp.append(indexes[i][1])\n",
        "\n",
        "    pred_corresp = [corresp[predicte] for predicted in y_pred]\n",
        "    acc = np.sum(pred_corresp == y_t) / float(len(y_t))\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHk9axm2bJJ0",
        "colab_type": "code",
        "outputId": "ec90a092-8cf9-4cdc-8b18-d5bdda1b5aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "epoc =500\n",
        "for i in range(epoc):\n",
        "    for image,label in train_ds:\n",
        "        train_step(image,label,100)\n",
        "    #print( train_loss1.result())  \n",
        "    #print( train_loss2.result())\n",
        "    print( train_loss.result())\n",
        "    #print(compute_accuracy(np.argmax(Activation('softmax')(model1(x_train)).astype(np.float32),y_train.astype(np.float32).,10))\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"gradients/model_2/conv2d/Conv2D_grad/Conv2DBackpropInput:0\", shape=(100, 28, 28, 1), dtype=float32)\n",
            "Tensor(\"gradients/model_2/conv2d/Conv2D_grad/Conv2DBackpropInput:0\", shape=(100, 28, 28, 1), dtype=float32)\n",
            "tf.Tensor(-1.7259059, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.7578505, shape=(), dtype=float32)\n",
            "tf.Tensor(-1.7696879, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f3c4e006b050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print( train_loss1.result())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print( train_loss2.result())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    402\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \"\"\"\n\u001b[1;32m    588\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 589\u001b[0;31m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[1;32m    590\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m    591\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycTXOjlU6g_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.save_weights('/content/drive/My Drive/research_/weight_autoencoder_2048_0827/IMSAT_cifer10.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lONj1irYkVrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.load_weights('/content/drive/My Drive/research_/weight_autoencoder_2048_0827/IMSAT_mnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ-cuZIn4pjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x_test[0:20]\n",
        "x = Activation('softmax')(model1(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiVdLxu6iXHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk3TXST5i1Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB14Tuiv8M6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xi = []\n",
        "for i in range(10000):\n",
        "    print(np.argmax(x[i]))\n",
        "    xi.append(np.argmax(x[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7H0f-4j89gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xi.count(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaXF0UBRNK1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(10):\n",
        "    x+=x[1][i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3iuBxAVNo8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[1][0]+x[1][1]+x[1][2]+x[1][3]+x[1][4]+x[1][5]+x[1][6]+x[1][7]+x[1][8]+x[1][9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TJB_IHbNtqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(x[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i_RcL6RNwim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}