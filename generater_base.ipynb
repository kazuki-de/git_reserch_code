{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2048, 2048, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2048, 2048, 16)    2368      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2048, 2048, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1024, 1024, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1024, 1024, 32)    12832     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1024, 1024, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 512, 512, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 512, 512, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 512, 512, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 16)        50192     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               2097280   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,181,555\n",
      "Trainable params: 2,181,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(2048, 2048, 3))\n",
    "x = Conv2D(16, (7, 7), padding='same')(input_img)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (5, 5), padding='same')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(16, (7, 7), padding='same',strides=16)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dense(3)(x)\n",
    "out = Activation(\"softmax\")(x)\n",
    "model = Model(input_img, out)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "weights_path = '/mnt/Doc/weight/Autoencoder/256/best_weight_0426.h5' \n",
    "assert os.path.exists(weights_path), 'Model weights not found '\n",
    "f = h5py.File(weights_path)\n",
    "layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
    "weight_value_tuples = []\n",
    "\n",
    "for k, name in enumerate(layer_names):\n",
    "    if k >= 9:\n",
    "        # 全結合層の重みは読み込まない\n",
    "        break\n",
    "    g = f[name]\n",
    "    weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
    "    if len(weight_names):\n",
    "        weight_values = [g[weight_name] for weight_name in weight_names]\n",
    "        layer = model.layers[k]\n",
    "        symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n",
    "        if len(weight_values) != len(symbolic_weights):\n",
    "            raise Exception('Layer #' + str(k) +\n",
    "                            ' (named \"' + layer.name +\n",
    "                            '\" in the current model) was found to '\n",
    "                            'correspond to layer ' + name +\n",
    "                            ' in the save file. '\n",
    "                            'However the new layer ' + layer.name +\n",
    "                            ' expects ' + str(len(symbolic_weights)) +\n",
    "                            ' weights, but the saved weights have ' +\n",
    "                            str(len(weight_values)) +' elements.')\n",
    "        weight_value_tuples += zip(symbolic_weights, weight_values)\n",
    "K.batch_set_value(weight_value_tuples)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "for layer in model.layers[:9]:\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2048, 2048, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2048, 2048, 16)    2368      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2048, 2048, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1024, 1024, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1024, 1024, 32)    12832     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1024, 1024, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 512, 512, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 512, 512, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 512, 512, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 16)        50192     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               2097280   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,215,251\n",
      "Trainable params: 2,181,555\n",
      "Non-trainable params: 33,696\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataGenerator(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "    #file_pathはメタCSVでーたのこと\n",
    "    def flow_from_directory(self, file_path, classes, batch_size=1):\n",
    "        # LabelEncode(classをint型に変換)するためのdict\n",
    "        blunc=np.empty((batch_size, 2048, 2048, 3), np.float32)\n",
    "        blunc_l=np.empty((batch_size), np.float32)\n",
    "        \n",
    "        #LabelEncode(classをint型に変換)するためのdict\n",
    "        classes = {v: i for i, v in enumerate(sorted(classes))}\n",
    "        file_path = pd.read_csv(file_path)\n",
    "        boss_dir = \"/mnt/Doc\"\n",
    "        while True:\n",
    "            # ディレクトリから画像のパスを取り出す\n",
    "            for i in range(len(file_path)):\n",
    "                # 画像を読み込みRGBへの変換、Numpyへの変換を行い、配列(self.iamges)に格納\n",
    "                path = file_path.loc[i][\"path1\"]\n",
    "                #print(i)\n",
    "                with Image.open(path) as f:\n",
    "                    self.images.append((np.asarray(f.convert('RGB'), dtype=np.float32))/255)  \n",
    "                # ファイル名からラベルを取り出し、配列(self.labels)に格納\n",
    "                #_, y = path.stem.split('_')\n",
    "                label = file_path.loc[i][\"type\"]\n",
    "                self.labels.append(to_categorical(classes[label],len(classes)))\n",
    "                # ここまでを繰り返し行い、batch_sizeの数だけ配列(self.iamges, self.labels)に格納\n",
    "                # batch_sizeの数だけ格納されたら、戻り値として返し、配列(self.iamges, self.labels)を空にする\n",
    "                if len(self.images)== batch_size:\n",
    "                    print(len(self.images))\n",
    "                    inputs = np.asarray(self.images,dtype=np.float32)\n",
    "                    targets = np.asarray(self.labels,dtype=np.float32)\n",
    "                    print(len(self.images))\n",
    "                    self.reset()\n",
    "                    yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = pathlib.Path('/path/to/test/')\n",
    "x = pd.read_csv(\\\"/mnt/Doc/2048pix_tissue_all/RGBmean<190.csv\")\n",
    "train_dir = \"/mnt/Doc/2048pix_tissue_all/train_1000.csv\"\n",
    "test_dir = \"/mnt/Doc/2048pix_tissue_all/val_300.csv\"\n",
    "train_len = len(pd.read_csv(train_dir))\n",
    "print(train_len)\n",
    "test_len = len(pd.read_csv(test_dir))\n",
    "test_datagen = ImageDataGenerator(),\n",
    "train_datagen = ImageDataGenerator()\n",
    "classes =[\"PI\",\"PP\",\"TRU\"],\n",
    "batchsize = 3\n",
    "model.fit_generator(\n",
    "    generator=train_datagen.flow_from_directory(train_dir, classes),\n",
    "    steps_per_epoch=999/3,\\n\",\n",
    "    epochs=3000,\\n\",\n",
    "    verbose=2,\\n\",\n",
    "    #validation_data=test_datagen.flow_from_directory(test_dir, classes),\\n\",\n",
    "    #validation_steps=int(test_len / batchsize)\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0b5a548ffcc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/kanayalab/Documents/2048pix tissue all/train_1000.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read_csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"/home/kanayalab/Documents/2048pix tissue all/train_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
