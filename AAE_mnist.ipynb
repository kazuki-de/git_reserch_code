{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AAE_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazuki-de/git_reserch_code/blob/master/AAE_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cibTvlKWs5a",
        "colab_type": "code",
        "outputId": "692ab96e-8893-44de-fb31-95f81bfbcb60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0rc0\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation , Softmax, MaxPool2D,UpSampling2D, Input, BatchNormalization, add, AveragePooling2D,InputLayer\n",
        "from tensorflow.keras import Model,Sequential\n",
        "import datetime\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from PIL import Image\n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "import tensorflow_hub as hub\n",
        " \n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import time\n",
        "\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import imageio\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 380.5MB 38kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 31.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 27.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrt_fsnGWwB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea0718d4-2389-46dc-8b44-6cab7cc1eb19"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "#x_train  = x_train.reshape(60000, 784)\n",
        "#x_test   = x_test.reshape(10000, 784)\n",
        "#x_train  = x_train.astype('float32')/255.0\n",
        "#x_test   = x_test.astype('float32')/255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "#x_train = x_train[..., tf.newaxis]\n",
        "#x_test = x_test[..., tf.newaxis]\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).batch(100)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(100)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0cujY2FWwco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUF = 60000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "TEST_BUF = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-8UDakCgE7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encode(Model):\n",
        "  def __init__(self,dimension):\n",
        "    super(Encode, self).__init__()\n",
        "    self.conv1 = Conv2D(8,(7,7),padding=\"same\", activation='relu', name='Conv1')\n",
        "    self.pool1 = MaxPool2D((2, 2), padding='same', name='Maxpool1')\n",
        "    self.conv2 = Conv2D(16,(5,5), padding=\"same\",activation='relu', name='Conv2')\n",
        "    self.pool2 = MaxPool2D((2, 2), padding='same', name='Maxpool2')\n",
        "    self.conv3 = Conv2D(16,(3,3),padding=\"same\", activation='relu', name='Conv3')\n",
        "    self.pool3 = MaxPool2D((2, 2), padding='same', name='Maxpool3')\n",
        "    self.Dense = Dense(dimention)\n",
        "    \n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.pool3(x)\n",
        "    return self.Dense(x)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH0u0rjscOo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decode(Model):\n",
        "  def __init__(self,dimension):\n",
        "    super(Decode, self).__init__()\n",
        "    self.Dense = Dense(dimension,activation=\"relu\")\n",
        "    self.Reshape = Reshape(target_shape=(32, 32, 16))\n",
        "    self.conv4 = Conv2D(16,(3,3),padding=\"same\", activation='relu', name='Conv4')\n",
        "    self.uppool1 = UpSampling2D((2, 2), name='Upsumpl1')\n",
        "    self.conv5 = Conv2D(16,(5,5), padding='same',activation='relu', name='Conv5')\n",
        "    self.uppool2 = UpSampling2D((2, 2), name='Upsumpl2')\n",
        "    self.conv6 =  Conv2D(8,(7,7), padding='same',activation='relu', name='Conv6')\n",
        "    self.uppool3 = UpSampling2D((2, 2), name='Upsumpl3')\n",
        "    self.conv7 = Conv2D(3,(3,3), padding='same',activation='relu', name='Conv7')\n",
        "  def call(self, x):\n",
        "    x = self.Dense(x)\n",
        "    x = self.Reshape(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.uppool1(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.uppool2(x)\n",
        "    x = self.conv6(x)\n",
        "    x = self.uppool3(x)\n",
        "    return self.conv7(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tclIezbcrqyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class discriminator_z(Model):\n",
        "    def __init__(self):\n",
        "        super(Decode, self).__init__()\n",
        "        self.dense1 = Dense(1000, activation='relu')\n",
        "        self.dense2 = Dense(512, activation='relu')\n",
        "        self.dense3 = Dense(1,, activation='relu')\n",
        "        self.noise = tf.keras.layers.GaussianNoise(stddev=0.3)\n",
        "    def call(self, x):\n",
        "        x = self.noise(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        return self.dense3(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95IsxqSOCsvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class discriminator_y(Model):\n",
        "    def __init__(self):\n",
        "        super(Decode, self).__init__()\n",
        "        self.dense1 = Dense(1000, activation='relu')\n",
        "        self.dense2 = Dense(512, activation='relu')\n",
        "        self.dense3 = Dense(1,, activation='relu')\n",
        "        self.noise = tf.keras.layers.GaussianNoise(stddev=0.3)\n",
        "    def call(self, x):\n",
        "        x = self.noise(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        return self.dense3(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEMb1ZVpdVbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AAE(Model):\n",
        "    def __init__(self, latent_dim,ndim_x=28*28, ndim_y=16, ndim_z=10, ndim_h=1000):\n",
        "        self.ndim_x = ndim_x\n",
        "        self.ndim_y = ndim_y\n",
        "        self.ndim_z = ndim_z\n",
        "        self.ndim_h = ndim_h\n",
        "        super(AAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.Encoder = Encoder()\n",
        "        self.Decoder = Decoder()\n",
        "        self.Encoder_y = Dense(ndim_y)\n",
        "        self.Encoder_z = Dense(ndim_z)\n",
        "        self.decoder.merge_y = Dense(ndim_h,use_bias=False)\n",
        "\t\tself.decoder.merge_z = Dense(ndim_h,use_bias=False)\n",
        "\t\t\n",
        "        self.discriminator_y = discriminator_y\n",
        "        self.discriminator_z = discriminator_z\n",
        "        \n",
        "    def encode(self, x, apply_softmax = True):\n",
        "        encode1 = self.Encoder(x)\n",
        "        encode_y = self.Encoder_y(encode1)\n",
        "        encode_z = self.Encoder_z(encode1)\n",
        "        if apply_softmax:\n",
        "            encode_y = Activation(\"softmax\")(encode_y)\n",
        "        return encode_y, encode_z\n",
        "    \n",
        "    def discriminate_z(self, z, apply_softmax=False):\n",
        "\t\tlogit = self.discriminator_z(z)\n",
        "\t\tif apply_softmax:\n",
        "\t\t\treturn Activation(\"softmax\")(logit)\n",
        "\t\treturn logit\n",
        "    def discriminate_y(self, y, apply_softmax=False):\n",
        "\t\tlogit = self.discriminator_y(y)\n",
        "\t\tif apply_softmax:\n",
        "\t\t\treturn Activation(\"softmax\")(logit)\n",
        "\t\treturn logit\n",
        "    def decode_yz_x(self, y, z):\n",
        "\t\tmerge = self.decoder.merge_y(y) + self.decoder.merge_z(z)\n",
        "\t\tmerge = Activation(\"relu\")(merge)\n",
        "\t\treturn self.Decoder(merge)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDxENzQiyl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_squere_error(x,x_reconst):\n",
        "    reconst_loss = (x_reconst - x) ** 2\n",
        "    reconst_loss = tf.reduce_mean(reconst_loss, axis=[1,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAq3V6_Zfi6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teGyenwcWxkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reconstract_loss(x_u):\n",
        "    y_onehot_u, z_u = model.encode_x_yz(x_u, apply_softmax_y=True)\n",
        "    x_reconstruction_u = model.decode_yz_x(y_onehot_u, z_u)\n",
        "    loss_mean = mean_squere_error(x_u,x_reconstruction_u)\n",
        "    return tf.reduce_mean(loss_mean)       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3AfEXgeWx5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adversarial_phase(model,x_u,batchsize):\n",
        "    \n",
        "    class_true = np.zeros(batchsize, dtype=np.int32)\n",
        "\tclass_fake = np.ones(batchsize, dtype=np.int32)\n",
        "    y_onehot_fake_u, z_fake_u = model.encode_x_yz(x_u, apply_softmax_y=True)\n",
        "    z_ture = tf.random.normal(shape=z_fake_u,mean=0.0,stddev=1.0,dtype=tf.dtypes.float32)\n",
        "    y_onehot_true = \n",
        "    #y_onehot_true = sampler.onehot_categorical(args.batchsize, model.ndim_y)\n",
        "\n",
        "    dz_true = model.discriminate_z(z_true, apply_softmax=True)\n",
        "    dz_fake = model.discriminate_z(z_fake_u, apply_softmax=True)\n",
        "    dy_true = model.discriminate_y(y_onehot_true, apply_softmax=True)\n",
        "    dy_fake = model.discriminate_y(y_onehot_fake_u, apply_softmax=True)\n",
        "\n",
        "    #discriminator_z_confidence_true = float(xp.mean(F.softmax(dz_true).data[:, 0]))\n",
        "    #discriminator_z_confidence_fake = float(xp.mean(F.softmax(dz_fake).data[:, 1]))\n",
        "    #discriminator_y_confidence_true = float(xp.mean(F.softmax(dy_true).data[:, 0]))\n",
        "    #discriminator_y_confidence_fake = float(xp.mean(F.softmax(dy_fake).data[:, 1]))\n",
        "\n",
        "    loss_discriminator_z = tf.keras.losses.BinaryCrossentropy(dz_true, class_true) + tf.keras.losses.BinaryCrossentropy(dz_fake, class_fake)\n",
        "    loss_discriminator_y = tf.keras.losses.BinaryCrossentropy(dy_true, class_true) + tf.keras.losses.BinaryCrossentropy(dy_fake, class_fake)\n",
        "    loss_discriminator = loss_discriminator_z + loss_discriminator_y\n",
        "    return loss_discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzM2bZVHWyNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_phase(model,x_u,batchsize):\n",
        "    class_true = np.zeros(batchsize, dtype=np.int32)\n",
        "\tclass_fake = np.ones(batchsize, dtype=np.int32)\n",
        "    y_onehot_fake_u, z_fake_u = model.encode_x_yz(x_u, apply_softmax_y=True)\n",
        "\n",
        "    dz_fake = model.discriminate_z(z_fake_u, apply_softmax=True)\n",
        "    dy_fake = model.discriminate_y(y_onehot_fake_u, apply_softmax=True)\n",
        "\n",
        "    loss_generator = tf.keras.losses.BinaryCrossentropy(dz_fake, class_true) + tf.keras.losses.BinaryCrossentropy(dy_fake, class_true)\n",
        "    return loss_generator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad6pScgq57T1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(model,x_u,batch_size,optimizer1,optimizer2,optimizer3,train_loss):\n",
        "    with tf.GradientTape() as tape1,tf.GradientTape() as tape2, tf.GradientTape() as tape3:\n",
        "        loss1 = reconstract_loss(x_u)\n",
        "        loss2 = adversarial_phase(model,x_u,batchsize)\n",
        "        loss3 = generator_phase(model,x_u,batchsize)\n",
        "    gradients1 = tape1.gradient(loss1, model.trainable_variables)\n",
        "    gradients2 = tape2.gradient(loss2, model.trainable_variables)\n",
        "    gradients3 = tape3.gradient(loss3, model.trainable_variables)\n",
        "    optimizer1.apply_gradients(zip(gradients1, model.trainable_variables))\n",
        "    optimizer2.apply_gradients(zip(gradients2, model.trainable_variables))    \n",
        "    optimizer3.apply_gradients(zip(gradients3, model.trainable_variables))\n",
        "    loss = loss1 + loss2 +loss3\n",
        "    train_loss(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SH2-wRrAX5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_shape = (28, 28, 1)\n",
        "latent_dim = 200\n",
        "train_loss = tf.keras.metrics.Sum(name='train_loss')\n",
        "opt1 = tf.keras.optimizers.Adam(1e-4)\n",
        "opt2 = tf.keras.optimizers.Adam(1e-4)\n",
        "opt3 = tf.keras.optimizers.Adam(1e-4)\n",
        "model = AAE()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBUkjTXZAoV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_dir = \"/content/drive/My Drive/research_/weight_AAE_mnist\"\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)\n",
        "manager = tf.train.CheckpointManager(ckpt, c_dir, max_to_keep=1)\n",
        "ckpt.restore(manager.latest_checkpoint)\n",
        "\n",
        "if manager.latest_checkpoint:\n",
        "    print(\"Restored from {}\".format(manager.latest_checkpoint))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGuD04bnA8YX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2000\n",
        "batch_size = 100\n",
        "log_path = \"/content/drive/My Drive/research_//weight_AAE_mnist/log.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAPwn4B9BALX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "number = 1\n",
        "cols = [\"epoch\",\"loss\",\"Saved\"]\n",
        "df = pd.DataFrame(index=[],columns=cols)\n",
        "if(os.path.exists(log_path)):\n",
        "    df= pd.read_csv(log_path)\n",
        "    print(log_path+\"is exist. loaded csv file\")\n",
        "    number = df[\"epoch\"].max()\n",
        "    loss_max = df[\"loss\"].max()\n",
        "    print(loss_max)\n",
        "print(number)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdbyYbrOBEF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    start_time = time.time()\n",
        "    for train_x, train_y in train_ds:\n",
        "        #print(x_l)\n",
        "        train_step(model,train_x,batch_size,opt1,opt2,opt3,train_loss)\n",
        "    print(epoch)\n",
        "    print(train_loss.result())\n",
        "    if number==1:\n",
        "        manager.save()\n",
        "        print(\"saved\")\n",
        "    if number!=1:\n",
        "        if df[\"loss\"].max()<=elbo:\n",
        "            manager.save()\n",
        "            a = \"saved\"\n",
        "            print(a)\n",
        "        else:\n",
        "            a = \"not saved\"\n",
        "            print(a)\n",
        "    number+=1\n",
        "    elbo_np = train_loss.result().numpy()\n",
        "    record = pd.Series([number,elbo_np,a],index = cols)\n",
        "    df = df.append(record,ignore_index=True)\n",
        "    df.to_csv(log_path,index=False)   \n",
        "    #if epoch%40==0:\n",
        "        #manager.save()\n",
        "    \n",
        "    \n",
        "    end_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}