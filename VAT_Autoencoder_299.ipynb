{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Autoencoder 128_128pix (1).ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"MuRyGRIvxBP2","colab_type":"code","outputId":"c15fee0c-9c9c-4b39-e040-1673d7e77a25","executionInfo":{"status":"ok","timestamp":1560920640947,"user_tz":-540,"elapsed":3615,"user":{"displayName":"出口和樹","photoUrl":"https://lh6.googleusercontent.com/-jY1R1tjVlFI/AAAAAAAAAAI/AAAAAAAAACk/B4c1AfAbREQ/s64/photo.jpg","userId":"00768786214145128005"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from PIL import Image\n","from keras.objectives import binary_crossentropy, mean_squared_error\n","import numpy as np\n","from functools import reduce\n","from keras.engine.topology import Input, Network\n","from keras.engine.training import Model\n","#from keras.models import to_list\n","np.random.seed(1337)  # for reproducibility\n","from keras.utils.generic_utils import to_list\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Flatten, Dropout,GlobalAveragePooling2D\n","from keras.models import Model\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.utils import np_utils\n","from keras import backend as K\n","from keras.optimizers import SGD\n","from keras.callbacks import LearningRateScheduler\n","import pandas as pd\n","from PIL import Image"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MEZuNxAl0HrB","colab_type":"code","outputId":"9398aa72-1c95-4d22-a834-7acb825881b3","executionInfo":{"status":"ok","timestamp":1560920640950,"user_tz":-540,"elapsed":3588,"user":{"displayName":"出口和樹","photoUrl":"https://lh6.googleusercontent.com/-jY1R1tjVlFI/AAAAAAAAAAI/AAAAAAAAACk/B4c1AfAbREQ/s64/photo.jpg","userId":"00768786214145128005"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lEIVYrgLxBQG","colab_type":"code","colab":{}},"source":["batch_size = 16\n","num_classes = 10\n","epochs = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvlauEcQxBQO","colab_type":"code","colab":{}},"source":["train=np.load(\"/content/drive/My Drive/256_npy/picture.npy\")\n","#train_label=np.load(\"/mnt/Doc/reserch1/train_type.npy\")\n","##test=np.load(\"/mnt/Doc/512pix_to_128pix/npy/128pix_testpicture.npy\")\n","val = np.load(\"/content/drive/My Drive/256_npy/picture_val.npy\")\n","#test_label=np.load(\"/mnt/Doc/reserch1/test_type.npy\")\n","\n","#x_train = train.astype('float32')\n","#x_test = test.astype('float32')\n","#x_val = val.astype('float32')\n","train /= 255\n","#x_test /= 255\n","val /=255\n","#del train\n","#del test\n","#del val"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CjsJgurx3hL","colab_type":"code","colab":{}},"source":["SAMPLE_SIZE = 0\n","\n","batch_size = 16\n","nb_classes = 10\n","nb_epoch = 1\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","# number of convolutional filters to use\n","nb_filters = 32\n","# size of pooling area for max pooling\n","pool_size = (2, 2)\n","# convolution kernel size\n","kernel_size = (3, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yzz4vHGx3-x","colab_type":"code","colab":{}},"source":["def main(data, use_dropout, use_vat):\n","    np.random.seed(1337)  # for reproducibility\n","\n","    # the data, shuffled and split between train and test sets\n","    #(X_train, y_train), (X_test, y_test) = data\n","\n","    \n","    #X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n","    #X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n","    #input_shape = (img_rows, img_cols, 1)\n","\n","    X_train = train.astype('float32')\n","    X_test = val.astype('float32')\n","    X_train /= 255.\n","    X_test /= 255.\n","\n","    # convert class vectors to binary class matrices\n","    #y_train = np_utils.to_categorical(y_train, nb_classes)\n","    #y_test = np_utils.to_categorical(y_test, nb_classes)\n","\n","    #if SAMPLE_SIZE:\n","    #   X_train = X_train[:SAMPLE_SIZE]\n","    #   y_train = y_train[:SAMPLE_SIZE]\n","    #   X_test = X_test[:SAMPLE_SIZE]\n","    #   y_test = y_test[:SAMPLE_SIZE]\n","    \n","    input_layer =(256,256,3)\n","    print(\"start: use_dropout=%s, use_vat=%s\" % (use_dropout, use_vat))\n","    my_model = MyModel(input_layer, use_dropout, use_vat).build()\n","    my_model1 = my_model.save_best(\"/content/drive/My Drive/256_npy/best_weight.h5\")\n","    my_model1.training(X_train, X_train, X_test, X_test,epoch=13)\n","    my_model1.weight_save(\"/content/drive/My Drive/research_/weight/wight_vat1.h5\")\n","    #score = my_model.model.evaluate(X_test, y_test, verbose=0)\n","    #print(\"finish: use_dropout=%s, use_vat=%s: score=%s, accuracy=%s\" % (use_dropout, use_vat, score[0], score[1]))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vdw-_znVx7hi","colab_type":"code","colab":{}},"source":["class MyModel:\n","    model = None\n","\n","    def __init__(self, input_shape, use_dropout=True, use_vat=True):\n","        self.input_shape = input_shape\n","        self.use_dropout = use_dropout\n","        self.use_vat = use_vat\n","\n","    def build(self):\n","        input_layer = Input(self.input_shape)\n","        output_layer = self.core_data_flow(input_layer)\n","        if self.use_vat:\n","            self.model = VATModel(input_layer, output_layer).setup_vat_loss()\n","        else:\n","            self.model = Model(input_layer, output_layer)\n","        return self\n","    \n","    def  save_best(self,path_):\n","        self.modelCheckpoint = ModelCheckpoint(filepath =path_,\n","                                 monitor=\"val_loss\",\n","                                 verbose=1,\n","                                 save_best_only=True,\n","                                 save_weights_only=True,\n","                                 mode=\"min\",\n","                                 period=1)\n","        return self\n","    \n","    def core_data_flow(self, input_layer):\n","        x = Conv2D(4, (7, 7), padding='same')(input_layer)\n","        #x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = MaxPooling2D((2, 2), padding='same')(x)\n","        x = Conv2D(8, (5, 5), padding='same')(x)\n","        #x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = MaxPooling2D((2, 2), padding='same')(x)\n","        x = Conv2D(16, (3, 3), padding='same')(x)\n","        #x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        encoded = MaxPooling2D((2, 2), padding='same')(x)\n","\n","        x = Conv2D(16, (3, 3), padding='same')(encoded)\n","        #x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = UpSampling2D((2, 2))(x)\n","        x = Conv2D(8, (5, 5), padding='same')(x)\n","        #x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = UpSampling2D((2, 2))(x)\n","        x = Conv2D(4, (7, 7), padding='same')(x)\n","        #x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = UpSampling2D((2, 2))(x)\n","        x = Conv2D(3, (3, 3), padding='same')(x)\n","        #x = BatchNormalization()(x)\n","        decoded = Activation('relu')(x)\n","        \n","        return decoded\n","    def weight_save(self,path):\n","        self.model.save_weights(path)\n","    \n","   \n","        \n","    \n","    def training(self, X_train, y_train, X_test, y_test,epoch):\n","        self.model.compile(loss=\"mean_squared_error\", optimizer='adam', metrics=['accuracy'])\n","        np.random.seed(1337)  # for reproducibility\n","        self.model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epoch,\n","                       verbose=1, validation_data=(X_test, y_test),callbacks=[self.modelCheckpoint])\n","     \n","\n","\n","class VATModel(Model):\n","    _vat_loss = None\n","\n","    def setup_vat_loss(self, eps=1, xi=10, ip=1):\n","        self._vat_loss = self.vat_loss(eps, xi, ip)\n","        return self\n","\n","\n","    def vat_loss(self, eps, xi, ip):\n","        normal_outputs = [K.stop_gradient(x) for x in to_list(self.outputs)]\n","        d_list = [K.random_normal(K.shape(x)) for x in self.inputs]\n","        print(d_list)\n","\n","        for _ in range(ip):\n","            new_inputs = [x + self.normalize_vector(d)*xi for (x, d) in zip(self.inputs, d_list)]\n","            new_outputs = to_list(self.call(new_inputs))\n","            klds = [K.sum(self.kld(normal, new)) for normal, new in zip(normal_outputs, new_outputs)]\n","            kld = reduce(lambda t, x: t+x, klds, 0)\n","            d_list = [K.stop_gradient(d) for d in K.gradients(kld, d_list)]\n","\n","        new_inputs = [x + self.normalize_vector(d) * eps for (x, d) in zip(self.inputs, d_list)]\n","        y_perturbations = to_list(self.call(new_inputs))\n","        klds = [K.mean(self.kld(normal, new)) for normal, new in zip(normal_outputs, y_perturbations)]\n","        kld = reduce(lambda t, x: t + x, klds, 0)\n","        return kld\n","\n","    @staticmethod\n","    def normalize_vector(x):\n","        z = K.sum(K.batch_flatten(K.square(x)), axis=1)\n","        while K.ndim(z) < K.ndim(x):\n","            z = K.expand_dims(z, axis=-1)\n","        return x / (K.sqrt(z) + K.epsilon())\n","\n","    @staticmethod\n","    def kld(p, q):\n","        v = p * (K.log(p + K.epsilon()) - K.log(q + K.epsilon()))\n","        return K.sum(K.batch_flatten(v), axis=1, keepdims=True)\n","\n","\n","data = mnist.load_data()\n","#main(data, use_dropout=False, use_vat=False)\n","#main(data, use_dropout=True, use_vat=False)\n","#main(data, use_dropout=False, use_vat=True)\n","main(data, use_dropout=True, use_vat=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X16kT087xBQa","colab_type":"code","colab":{}},"source":[".modell.save_weight(\"/content/drive/My Drive/research_/weight/wight_vat1.h5\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLRgtzhv1gSH","colab_type":"code","colab":{}},"source":["my_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRA1x-wU1zit","colab_type":"code","colab":{}},"source":["score = my_model.model.evaluate(X_test, X_test, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TLZLC14RxBQm","colab_type":"code","colab":{}},"source":["#print('x_train shape:', x_train.shape)\n","print(train.shape[0], 'train samples')\n","#print(x_test.shape[0], 'test samples')\n","print(val.shape[0], 'val samples')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_2InAtIxBQu","colab_type":"code","colab":{}},"source":["# divide x_test into validation and test\n","#x_val = x_test[:900]\n","#x_test = x_test[900:]\n","#x_val_label = test_label[:900]\n","#x_test_label = test_label[900:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xjg5XQ13xBQz","colab_type":"code","colab":{}},"source":["#train_label_1=np_utils.to_categorical(train_label)\n","#test_label_1=np_utils.to_categorical(x_test_label)\n","#val_label_1=np_utils.to_categorical(x_val_label)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIwPP1RJxBQ6","colab_type":"code","colab":{}},"source":["#print(\"validation data: {0} \\ntest data: {1}\".format(x_val.shape, x_test.shape))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zUxx32DxOPG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0SKvAkxIxBQ_","colab_type":"code","colab":{}},"source":["input_img = Input(shape=(256, 256, 3))\n","x = Conv2D(4, (7, 7), padding='same')(input_img)\n","#x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(8, (5, 5), padding='same')(x)\n","#x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(16, (3, 3), padding='same')(x)\n","#x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","encoded = MaxPooling2D((2, 2), padding='same')(x)\n","\n","x = Conv2D(16, (3, 3), padding='same')(encoded)\n","#x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = UpSampling2D((2, 2))(x)\n","x = Conv2D(8, (5, 5), padding='same')(x)\n","#x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = UpSampling2D((2, 2))(x)\n","x = Conv2D(4, (7, 7), padding='same')(x)\n","#x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = UpSampling2D((2, 2))(x)\n","x = Conv2D(3, (3, 3), padding='same')(x)\n","#x = BatchNormalization()(x)\n","decoded = Activation('relu')(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YC4Q5dphxBRm","colab_type":"code","colab":{}},"source":["model = Model(input_img, decoded)\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8iFgJ_sbxBSb","colab_type":"code","colab":{}},"source":["modelCheckpoint = ModelCheckpoint(filepath =\"/mnt/Doc/weight/Autoencoder/256/best_weight_0507.h5\",\n","                                 monitor=\"val_loss\",\n","                                 verbose=1,\n","                                 save_best_only=True,\n","                                 save_weights_only=True,\n","                                 mode=\"min\",\n","                                 period=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lYrg_xexBSh","colab_type":"code","colab":{}},"source":["history = model.fit(train, train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(val, val),\n","                    callbacks=[modelCheckpoint],\n","                    shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLm53IQYxBSn","colab_type":"code","colab":{}},"source":["from datetime import datetime\n","x = datetime.now().strftime(\"%Y.%m.%d %H:%M:%S\")\n","y = datetime.now().strftime(\"%Y.%m.%d\")\n","new_file_pass = os.path.join(\"/mnt/Doc/Autoencoder_data\",y)\n","if os.path.exists(new_file_pass)==False:\n","    os.mkdir(new_file_pass)\n","else:\n","    pass\n","y1 = os.path.join(new_file_pass,\"weight\"+x+\".h5\")\n","z1 = os.path.join(new_file_pass,\"model\"+x+\".json\")\n","model.save_weights(y)\n","open(z1,\"w\").write(model.to_json())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7aMPYeIxBSs","colab_type":"code","colab":{}},"source":["open(\"autoencodermodel1.json\",\"w\").write(model.to_json())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"902vanFgxBSy","colab_type":"code","colab":{}},"source":["model.load_weights('/mnt/Doc/weight/Autoencoder/256/best_weight_0426.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAQW1YofxBS3","colab_type":"code","colab":{}},"source":["images = []\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-1W8TT9xBS7","colab_type":"code","colab":{}},"source":["images = []\n","path = \"/mnt/Doc/2048pix_tissue_all/TRU/TCGA-50-5935-01A-01-TS1_2048_files/8_15.jpeg\"\n","path = \"/mnt/Doc/2048pix_tissue_all/PP/TCGA-78-7160-01A-01-TS1_2048_files/6_5.jpeg\"\n","f = Image.open(path) \n","images.append((np.asarray(f.convert('RGB'), dtype=np.float32))/255)\n","del f\n","f1 = Image.open(path) \n","images.append((np.asarray(f1.convert('RGB'), dtype=np.float32))/255)\n","del f1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jwJKzL1txBTA","colab_type":"code","colab":{}},"source":["decoded_imgs=model.predict(images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHTtw4bUxBTJ","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"M4-1fMsYxBTS","colab_type":"code","colab":{}},"source":["decoded_imgs.astype('uint8')\n","plt.imshow(decoded_imgs[9])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3KlYk2mxBTi","colab_type":"code","colab":{}},"source":["plt.imshow(x_test[2])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gMh349KAxBTq","colab_type":"code","colab":{}},"source":["n=10\n","plt.figure(figsize=(20,4))\n","list1=range(len(val))\n","randam1=random.sample(list1,10)\n","for i in range(n):\n","    #オリジナル画像\n","    picture_num=randam1[i]\n","    ax=plt.subplot(2,n,i+1)\n","    plt.imshow(val[picture_num])\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    #変換後画像\n","    ax=plt.subplot(2,n,i+1+n)\n","    plt.imshow(decoded_imgs[picture_num])\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Ij9RkNOxBTv","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"As5njWYbxBT2","colab_type":"code","colab":{}},"source":["input_img = Input(shape=(128, 128, 3))\n","x = Conv2D(32, (7, 7), padding='same')(input_img)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(32, (5, 5), padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(32, (3, 3), padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","encoded = MaxPooling2D((2, 2), padding='same')(x)\n","x = Flatten()(encoded)\n","x = Dense(128)(x)\n","x = Activation(\"relu\")(x)\n","x = Dense(3)(x)\n","out = Activation(\"softmax\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1xj-NXUxBUB","colab_type":"code","colab":{}},"source":["model = Model(input_img, out)\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XET2QpXixBUS","colab_type":"code","colab":{}},"source":["import os \n","import h5py\n","from keras import backend as K\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOpaoG2mxBUa","colab_type":"code","colab":{}},"source":["weights_path = ''\n","\n","assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n","f = h5py.File(weights_path)\n","layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n","weight_value_tuples = []\n","for k, name in enumerate(layer_names):\n","    if k >= len(model.layers):\n","        # 全結合層の重みは読み込まない\n","        break\n","    g = f[name]\n","    weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n","    if len(weight_names):\n","        weight_values = [g[weight_name] for weight_name in weight_names]\n","        layer = model.layers[k]\n","        symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n","        if len(weight_values) != len(symbolic_weights):\n","            raise Exception('Layer #' + str(k) +\n","                            ' (named \"' + layer.name +\n","                            '\" in the current model) was found to '\n","                            'correspond to layer ' + name +\n","                            ' in the save file. '\n","                            'However the new layer ' + layer.name +\n","                            ' expects ' + str(len(symbolic_weights)) +\n","                            ' weights, but the saved weights have ' +\n","                            str(len(weight_values)) +\n","                            ' elements.')\n","        weight_value_tuples += zip(symbolic_weights, weight_values)\n","K.batch_set_value(weight_value_tuples)\n","f.close()\n","print('Model loaded.')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yq2VFk3xBUf","colab_type":"code","colab":{}},"source":["layer_names"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XhQ0QEYMxBUj","colab_type":"code","colab":{}},"source":["g = f[\"conv2d_15\"]\n","weight_names = [n.decode(\"utf8\") for n in g.attrs[\"weight_names\"]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVNX4_knxBUn","colab_type":"code","colab":{}},"source":["#メモリ使用量確認\n","def print_varsize():\n","    import types\n","    print(\"{}{: >15}{}{: >10}{}\".format('|','Variable Name','|','  Size','|'))\n","    print(\" -------------------------- \")\n","    for k, v in globals().items():\n","        if hasattr(v, 'size') and not k.startswith('_') and not isinstance(v,types.ModuleType):\n","            print(\"{}{: >15}{}{: >10}{}\".format('|',k,'|',str(v.size),'|'))\n","        elif hasattr(v, '__len__') and not k.startswith('_') and not isinstance(v,types.ModuleType):\n","            print(\"{}{: >15}{}{: >10}{}\".format('|',k,'|',str(len(v)),'|'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sF8D449ExBUr","colab_type":"code","colab":{}},"source":["print_varsize()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zuoiqjcJxBU0","colab_type":"code","colab":{}},"source":["del test_label_1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQdzOczUxBU5","colab_type":"code","colab":{}},"source":["x_val"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFT0XnYPxBVD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}