{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.load(\"/mnt/Doc/512pix_to_128pix/npy/128pix_trainpicture.npy\")\n",
    "#train_label=np.load(\"/mnt/Doc/reserch1/train_type.npy\")\n",
    "test=np.load(\"/mnt/Doc/512pix_to_128pix/npy/128pix_testpicture.npy\")\n",
    "val = np.load(\"/mnt/Doc/512pix_to_128pix/npy/128pix_validationpicture.npy\")\n",
    "#test_label=np.load(\"/mnt/Doc/reserch1/test_type.npy\")\n",
    "\n",
    "x_train = train.astype('float32')\n",
    "x_test = test.astype('float32')\n",
    "x_val = val.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_val /=255\n",
    "del train\n",
    "del test\n",
    "del val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (9000, 128, 128, 3)\n",
      "9000 train samples\n",
      "1500 test samples\n",
      "1500 val samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_val.shape[0], 'val samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide x_test into validation and test\n",
    "#x_val = x_test[:900]\n",
    "#x_test = x_test[900:]\n",
    "#x_val_label = test_label[:900]\n",
    "#x_test_label = test_label[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_label_1=np_utils.to_categorical(train_label)\n",
    "#test_label_1=np_utils.to_categorical(x_test_label)\n",
    "#val_label_1=np_utils.to_categorical(x_val_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"validation data: {0} \\ntest data: {1}\".format(x_val.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(128, 128, 3))\n",
    "x = Conv2D(16, (7, 7), padding='same')(input_img)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (5, 5), padding='same')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same')(encoded)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (5, 5), padding='same')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (7, 7), padding='same')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(3, (3, 3), padding='same')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "decoded = Activation('relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      2368      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        12832     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        51232     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 16)        25104     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 3)       435       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 147,395\n",
      "Trainable params: 147,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_img, decoded)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = ModelCheckpoint(filepath =\"/mnt/Doc/512pix_to_128pix/best_weight_0220.h5\",\n",
    "                                 monitor=\"val_loss\",\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True,\n",
    "                                 mode=\"min\",\n",
    "                                 period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 44s 5ms/step - loss: 0.0591 - val_loss: 0.0258\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02583, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0212 - val_loss: 0.0190\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02583 to 0.01898, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0194 - val_loss: 0.0174\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01898 to 0.01736, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0174 - val_loss: 0.0164\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01736 to 0.01642, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0166 - val_loss: 0.0158\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01642 to 0.01580, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0162 - val_loss: 0.0156\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01580 to 0.01557, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0159 - val_loss: 0.0155\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01557 to 0.01554, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 37s 4ms/step - loss: 0.0154 - val_loss: 0.0146\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01554 to 0.01459, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 37s 4ms/step - loss: 0.0150 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01459 to 0.01433, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01433\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0144 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01433 to 0.01410, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0142 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01410 to 0.01341, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01341\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01341 to 0.01299, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01299\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01299 to 0.01254, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0131 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01254 to 0.01239, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01239\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0128 - val_loss: 0.0122\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01239 to 0.01218, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01218 to 0.01195, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0124 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01195 to 0.01163, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01163 to 0.01152, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0121 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01152\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01152 to 0.01129, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 39s 4ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01129\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01129 to 0.01099, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01099\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01099\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01099 to 0.01069, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 39s 4ms/step - loss: 0.0118 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01069\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0128 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01069\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01069\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01069\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01069\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.01069 to 0.01051, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01051\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01051 to 0.01040, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01040\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.01040 to 0.01026, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01026\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01026\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.01026 to 0.01014, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01014 to 0.01011, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.01011 to 0.01003, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01003 to 0.00995, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00995\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00995 to 0.00980, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00980 to 0.00958, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00958\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00958\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00958\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00958 to 0.00939, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 39s 4ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00939\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00939\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00939\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0098 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00939 to 0.00935, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 39s 4ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00935 to 0.00932, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00932\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00932\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00932 to 0.00922, saving model to /mnt/Doc/512pix_to_128pix/best_weight_0220.h5\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0139 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00922\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0150 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00922\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0128 - val_loss: 0.0118\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00922\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00922\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00922\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00922\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00922\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00922\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00922\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 38s 4ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00922\n",
      "Epoch 71/100\n",
      "3136/9000 [=========>....................] - ETA: 23s - loss: 0.0106"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-856ad41e512c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelCheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, x_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, x_val),\n",
    "                    callbacks=[modelCheckpoint],\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "x = datetime.now().strftime(\"%Y.%m.%d %H:%M:%S\")\n",
    "y = datetime.now().strftime(\"%Y.%m.%d\")\n",
    "new_file_pass = os.path.join(\"/mnt/Doc/Autoencoder_data\",y)\n",
    "if os.path.exists(new_file_pass)==False:\n",
    "    os.mkdir(new_file_pass)\n",
    "else:\n",
    "    pass\n",
    "y1 = os.path.join(new_file_pass,\"weight\"+x+\".h5\")\n",
    "z1 = os.path.join(new_file_pass,\"model\"+x+\".json\")\n",
    "model.save_weights(y)\n",
    "open(z1,\"w\").write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"autoencodermodel1.json\",\"w\").write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs.astype('uint8')\n",
    "plt.imshow(decoded_imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "plt.figure(figsize=(20,4))\n",
    "list1=range(len(x_test))\n",
    "randam1=random.sample(list1,10)\n",
    "for i in range(n):\n",
    "    #オリジナル画像\n",
    "    picture_num=randam1[i]\n",
    "    ax=plt.subplot(2,n,i+1)\n",
    "    plt.imshow(x_test[picture_num])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    #変換後画像\n",
    "    ax=plt.subplot(2,n,i+1+n)\n",
    "    plt.imshow(decoded_imgs[picture_num])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(128, 128, 3))\n",
    "x = Conv2D(32, (7, 7), padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (5, 5), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(encoded)\n",
    "x = Dense(128)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dense(3)(x)\n",
    "out = Activation(\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_img, out)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import h5py\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights_path = ''\n",
    "\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
    "weight_value_tuples = []\n",
    "for k, name in enumerate(layer_names):\n",
    "    if k >= len(model.layers):\n",
    "        # 全結合層の重みは読み込まない\n",
    "        break\n",
    "    g = f[name]\n",
    "    weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
    "    if len(weight_names):\n",
    "        weight_values = [g[weight_name] for weight_name in weight_names]\n",
    "        layer = model.layers[k]\n",
    "        symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n",
    "        if len(weight_values) != len(symbolic_weights):\n",
    "            raise Exception('Layer #' + str(k) +\n",
    "                            ' (named \"' + layer.name +\n",
    "                            '\" in the current model) was found to '\n",
    "                            'correspond to layer ' + name +\n",
    "                            ' in the save file. '\n",
    "                            'However the new layer ' + layer.name +\n",
    "                            ' expects ' + str(len(symbolic_weights)) +\n",
    "                            ' weights, but the saved weights have ' +\n",
    "                            str(len(weight_values)) +\n",
    "                            ' elements.')\n",
    "        weight_value_tuples += zip(symbolic_weights, weight_values)\n",
    "K.batch_set_value(weight_value_tuples)\n",
    "f.close()\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = f[\"conv2d_15\"]\n",
    "weight_names = [n.decode(\"utf8\") for n in g.attrs[\"weight_names\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#メモリ使用量確認\n",
    "def print_varsize():\n",
    "    import types\n",
    "    print(\"{}{: >15}{}{: >10}{}\".format('|','Variable Name','|','  Size','|'))\n",
    "    print(\" -------------------------- \")\n",
    "    for k, v in globals().items():\n",
    "        if hasattr(v, 'size') and not k.startswith('_') and not isinstance(v,types.ModuleType):\n",
    "            print(\"{}{: >15}{}{: >10}{}\".format('|',k,'|',str(v.size),'|'))\n",
    "        elif hasattr(v, '__len__') and not k.startswith('_') and not isinstance(v,types.ModuleType):\n",
    "            print(\"{}{: >15}{}{: >10}{}\".format('|',k,'|',str(len(v)),'|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_varsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
